{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing And Transforming Features\n",
    "### Learn how to clean and prepare features for linear regression.\n",
    "\n",
    "##### Contents:\n",
    "- Intro to Feature Engineering\n",
    "- Features without missing values, but aren't in proper format for Linear Regression model\n",
    "    - Common issues:\n",
    "        - the column is not numerical (e.g. a zoning code represented using text)  \n",
    "        - the column is numerical but not ordinal (e.g. zip code values)\n",
    "        - the column is numerical but isn't representative of the type of relationship with the target column (e.g. year values)\n",
    "    - Selecting columns without missing values: `train[train.isnull().sum()[train.isnull().sum()==0].index]`\n",
    "    - Categorical Features\n",
    "        - pandas.Series.astype('category')\n",
    "        - pandas.Series.astype('category').cat.codes\n",
    "        - pandas.Series.astype('category').cat.codes.value_counts()\n",
    "    - Dummy Coding (creates `n` one-hot columns)\n",
    "        - dummy_cols = pd.get_dummies()\n",
    "    - Transforming Improper Numerical Features (e.g. `year`)\n",
    "- Dealing with missing values\n",
    "    - Remove rows containing missing values for specific columns \n",
    "    - Impute (or replace) missing values using a descriptive statistic from the column\n",
    "        - Selecting, Imputing\n",
    "        - pandas.DataFrame.fillna()\n",
    "    - Pros/Cons of each approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order                0\n",
      "PID                  0\n",
      "MS SubClass          0\n",
      "MS Zoning            0\n",
      "Lot Frontage       249\n",
      "Lot Area             0\n",
      "Street               0\n",
      "Alley             1351\n",
      "Lot Shape            0\n",
      "Land Contour         0\n",
      "Utilities            0\n",
      "Lot Config           0\n",
      "Land Slope           0\n",
      "Neighborhood         0\n",
      "Condition 1          0\n",
      "Condition 2          0\n",
      "Bldg Type            0\n",
      "House Style          0\n",
      "Overall Qual         0\n",
      "Overall Cond         0\n",
      "Year Built           0\n",
      "Year Remod/Add       0\n",
      "Roof Style           0\n",
      "Roof Matl            0\n",
      "Exterior 1st         0\n",
      "Exterior 2nd         0\n",
      "Mas Vnr Type        11\n",
      "Mas Vnr Area        11\n",
      "Exter Qual           0\n",
      "Exter Cond           0\n",
      "                  ... \n",
      "Bedroom AbvGr        0\n",
      "Kitchen AbvGr        0\n",
      "Kitchen Qual         0\n",
      "TotRms AbvGrd        0\n",
      "Functional           0\n",
      "Fireplaces           0\n",
      "Fireplace Qu       717\n",
      "Garage Type         74\n",
      "Garage Yr Blt       75\n",
      "Garage Finish       75\n",
      "Garage Cars          0\n",
      "Garage Area          0\n",
      "Garage Qual         75\n",
      "Garage Cond         75\n",
      "Paved Drive          0\n",
      "Wood Deck SF         0\n",
      "Open Porch SF        0\n",
      "Enclosed Porch       0\n",
      "3Ssn Porch           0\n",
      "Screen Porch         0\n",
      "Pool Area            0\n",
      "Pool QC           1459\n",
      "Fence             1163\n",
      "Misc Feature      1400\n",
      "Misc Val             0\n",
      "Mo Sold              0\n",
      "Yr Sold              0\n",
      "Sale Type            0\n",
      "Sale Condition       0\n",
      "SalePrice            0\n",
      "Length: 82, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/AmesHousing.txt', delimiter=\"\\t\")\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "\n",
    "train_null_counts = train.isnull().sum()\n",
    "print(train_null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Introduction\n",
    "\n",
    "To understand how linear regression works, we've stuck to using features from the training dataset that contained no missing values and were already in a convenient numeric representation. In this mission, we'll explore how to transform some of the the remaining features so we can use them in our model. Broadly, the process of processing and creating new features is known as [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering). **Feature engineering is a bit of an art and having knowledge in the specific domain (in this case real estate) can help you create better features.** In this mission, we'll focus on some domain-independent strategies that work for all problems.\n",
    "\n",
    "- In the first half of this mission, we'll focus only on columns that contain no missing values but still aren't in the proper format to use in a linear regression model. \n",
    "- In the latter half of this mission, we'll explore some ways to deal with missing values.\n",
    "\n",
    "Amongst the columns that don't contain missing values, some of the common issues include:\n",
    "\n",
    "- the column is not numerical (e.g. a zoning code represented using text)\n",
    "- the column is numerical but not ordinal (e.g. zip code values)\n",
    "- the column is numerical but isn't representative of the type of relationship with the target column (e.g. year values)\n",
    "\n",
    "Let's start by filtering the training set to just the columns containing no missing values.\n",
    "\n",
    "#### Instructions:\n",
    "- Select just the columns from the train data frame that contain no missing values.\n",
    "- Assign the resulting data frame, that contains just these columns, to df_no_mv.\n",
    "- Use the variables display to become familiar with these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>...</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Area Street Lot Shape  \\\n",
       "0      1  526301100           20        RL     31770   Pave       IR1   \n",
       "1      2  526350040           20        RH     11622   Pave       Reg   \n",
       "2      3  526351010           20        RL     14267   Pave       IR1   \n",
       "3      4  526353030           20        RL     11160   Pave       Reg   \n",
       "4      5  527105010           60        RL     13830   Pave       IR1   \n",
       "\n",
       "  Land Contour Utilities Lot Config    ...     Enclosed Porch 3Ssn Porch  \\\n",
       "0          Lvl    AllPub     Corner    ...                  0          0   \n",
       "1          Lvl    AllPub     Inside    ...                  0          0   \n",
       "2          Lvl    AllPub     Corner    ...                  0          0   \n",
       "3          Lvl    AllPub     Corner    ...                  0          0   \n",
       "4          Lvl    AllPub     Inside    ...                  0          0   \n",
       "\n",
       "  Screen Porch Pool Area Misc Val Mo Sold  Yr Sold  Sale Type  Sale Condition  \\\n",
       "0            0         0        0       5     2010        WD           Normal   \n",
       "1          120         0        0       6     2010        WD           Normal   \n",
       "2            0         0    12500       6     2010        WD           Normal   \n",
       "3            0         0        0       4     2010        WD           Normal   \n",
       "4            0         0        0       3     2010        WD           Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0     215000  \n",
       "1     105000  \n",
       "2     172000  \n",
       "3     244000  \n",
       "4     189900  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_mv = train[train_null_counts[train_null_counts == 0].index]\n",
    "df_no_mv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Categorical Features\n",
    "\n",
    "You'll notice that some of the columns in the data frame `df_no_mv` contain string values. If these columns contain only a limited set of uniuqe values, they're known as **categorical features**. As the name suggests, a categorical feature groups a specific training example into a specific *category*. Here are some examples from the dataset:\n",
    "\n",
    "    >>> train['Utilities'].value_counts()\n",
    "    AllPub    1457\n",
    "    NoSewr       2\n",
    "    NoSeWa       1\n",
    "    Name: Utilities, dtype: int64\n",
    "\n",
    "    >>> train['Street'].value_counts()\n",
    "    Pave    1455\n",
    "    Grvl       5\n",
    "\n",
    "    >>> train['House Style'].value_counts()\n",
    "    1Story    743\n",
    "    2Story    440\n",
    "    1.5Fin    160\n",
    "    SLvl       60\n",
    "    SFoyer     35\n",
    "    2.5Unf     11\n",
    "    1.5Unf      8\n",
    "    2.5Fin      3\n",
    "    \n",
    "To use these features in our model, we need to transform them into numerical representations. Thankfully, pandas makes this easy because the library has a special [categorical data type](https://pandas.pydata.org/pandas-docs/stable/categorical.html). We can convert any column that contains no missing values (or an error will be thrown) to the categorical data type using the `pandas.Series.astype()` method:\n",
    "\n",
    "    >>> train['Utilities'] = train['Utilities'].astype('categorical')\n",
    "    \n",
    "When a column is converted to the categorical data type, pandas assigns a code to each unique value in the column. Unless we access these values directly, most of the pandas manipulation operations that work for string columns will work for categorical ones as well.\n",
    "\n",
    "We need to use the `.cat` accessor followed by the `.codes` property to actually access the underlying numerical representation of a column:\n",
    "\n",
    "    >>> train['Utilities'].cat.codes\n",
    "    \n",
    "Let's convert all of the text columns that contain no missing values into the categorical data type.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- Convert all of the text columns in train to the categorical data type.\n",
    "- Select the Utilities column, return the categorical codes, and display the unique value counts for those codes: `train['Utilities'].cat.codes.value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS Zoning: 6\n",
      "Street: 2\n",
      "Lot Shape: 4\n",
      "Land Contour: 4\n",
      "Utilities: 3\n",
      "Lot Config: 5\n",
      "Land Slope: 3\n",
      "Neighborhood: 26\n",
      "Condition 1: 9\n",
      "Condition 2: 6\n",
      "Bldg Type: 5\n",
      "House Style: 8\n",
      "Roof Style: 6\n",
      "Roof Matl: 5\n",
      "Exterior 1st: 14\n",
      "Exterior 2nd: 16\n",
      "Exter Qual: 4\n",
      "Exter Cond: 5\n",
      "Foundation: 6\n",
      "Heating: 6\n",
      "Heating QC: 4\n",
      "Central Air: 2\n",
      "Electrical: 4\n",
      "Kitchen Qual: 5\n",
      "Functional: 7\n",
      "Paved Drive: 3\n",
      "Sale Type: 9\n",
      "Sale Condition: 5\n"
     ]
    }
   ],
   "source": [
    "text_cols = df_no_mv.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in text_cols:\n",
    "    print(col+\":\", len(train[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllPub    1457\n",
       "NoSewr       2\n",
       "NoSeWa       1\n",
       "Name: Utilities, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of how this looks (like strings) without accessing values directly\n",
    "train['Utilities'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas\n",
    "# pd.options.mode.chained_assignment = None  # default='warn'\n",
    "train = train.copy() # or can do this to remove warning (because train is a sub-df of `data`)\n",
    "# Pandas emits a UserWarning to warn you that modifying public does not modify \n",
    "# that other DataFrame. If modifying that other DataFrame is not what you intend \n",
    "# to do or is not an issue, then you are free to ignore the UserWarning.\n",
    "\n",
    "for col in text_cols:\n",
    "    train[col] = train[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1457\n",
       "2       2\n",
       "1       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Utilities'].cat.codes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Dummy Coding\n",
    "\n",
    "When we convert a column to the categorical data type, pandas assigns a number from `0` to `n-1` (where `n` is the number of unique values in a column) for each value. The drawback with this approach is that one of the assumptions of linear regression is violated here. Linear regression operates under the assumption that the features are linearly correlated with the target column. For a categorical feature, however, there's no actual numerical meaning to the categorical codes that pandas assigned for that colum. An increase in the `Utilities` column from `1` to `2` has no correlation value with the target column, and the categorical codes are instead used for uniqueness and exclusivity (the category associated with `0` is different than the one associated with `1`).\n",
    "\n",
    "The common solution is to use a technique called [dummy coding](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)). Instead of having a single column with `n` integer codes, we have `n` binary columns. Here's what that would look like for the `Utilities` column:\n",
    "\n",
    "| Utilities_AllPub | Utilities_NoSewr | Utilities_NoSeWa |\n",
    "|------------------|------------------|------------------|\n",
    "| 1                | 0                | 0                |\n",
    "| 1                | 0                | 0                |\n",
    "| 1                | 0                | 0                |\n",
    "| 1                | 0                | 0                |\n",
    "\n",
    "Because the original values for the first 4 rows were `AllPub`, in the new scheme, they contain the binary value for true (`1`) in the `Utilities_AllPub` column and `0` for the other 2 columns.\n",
    "\n",
    "Pandas thankfully has a convenience method to help us apply this transformation for all of the text columns called `pandas.get_dummies()`:\n",
    "\n",
    "    dummy_cols = pd.get_dummies()\n",
    "\n",
    "#### Instructions:\n",
    "- Convert all of the columns in text_cols from the train data frame into dummy columns.\n",
    "- Delete the original columns from text_cols from the train data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 236)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text cols to dummy cols\n",
    "dummy_cols = pd.get_dummies(train[text_cols])\n",
    "\n",
    "# drop original text cols\n",
    "train = train.drop(text_cols, axis=1)\n",
    "\n",
    "# concat train and dummy cols\n",
    "train = pd.concat([train, dummy_cols], axis=1)\n",
    "\n",
    "# check shape\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Transforming Improper Numerical Features\n",
    "\n",
    "In the last few screens, we focused on categorical values that were represented as text columns. Some of the numerical columns in the data set are *also* categorical and only have a limited set of unique values. We won't explicitly explore those coumns in this mission, but the feature transformation process is the same if the numbers used in those categories have no numerical meaning.\n",
    "\n",
    "Let's now look at numerical features that *aren't* categorical, but whose numerical representation needs to be improved. We'll focus on the `Year Remod/Add` and `Year Built` columns:\n",
    "\n",
    "    >>> train[['Year Remod/Add', 'Year Built']]\n",
    "    0   1960    1960\n",
    "    1   1961    1961\n",
    "    2   1958    1958\n",
    "    3   1968    1968\n",
    "    4   1998    1997\n",
    "    ...\n",
    "    \n",
    "The two main issues with these features are:\n",
    "\n",
    "- Year values aren't representative of how old a house is\n",
    "- The `Year Remod/Add` column doesn't actually provide useful information for a linear regression model\n",
    "\n",
    "The challenge with year values like `1960` and `1961` is that they don't do a good capture how old a house is. For example, a house that was built in `1960` but sold in `1980` was sold in half the time one built in `1960` and sold in `2000`. Instead of the years certain events happened, we want the difference between those years. We should create a new column that's the *difference* between both of these columns.    \n",
    "\n",
    "For this particular piece of information (years until remodeled), this is a sensible approach. Domain knowledge can help you understand how to best transform features to represent information well for a linear model. If you're ever confused about a feature or how it should be represented, reading scientific papers or posts by researchers in the specific domain is critical. Many winners of the [Kaggle data science competition](https://www.dataquest.io/m/239/processing-and-transforming-features/4/kaggle.com), for example, claim that their focus on data preparation and feature engineering combined with common machine learning models helped them win.\n",
    "\n",
    "#### Instructions:\n",
    "- Create a new column years_until_remod in the train data frame that represents the difference between Year Remod/Add (the later value) and Year Built (the earlier value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['years_until_remod'] = train['Year Remod/Add'] - train['Year Built']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Missing Values\n",
    "\n",
    "In the next few screens, we'll focus on handling columns with missing values. When values are missing in a column, there are two main approaches we can take:\n",
    "\n",
    "- Remove rows containing missing values for specific columns\n",
    "    - Pro: Rows containing missing values are removed, leaving only clean data for modeling\n",
    "    - Con: Entire observations from the training set are removed, which can reduce overall prediction accuracy\n",
    "- Impute (or replace) missing values using a descriptive statistic from the column\n",
    "    - Pro: Missing values are replaced with potentially similar estimates, preserving the rest of the observation in the model.\n",
    "    - Con: Depending on the approach, we may be adding noisy data for the model to learn\n",
    "    \n",
    "Given that we only have 1460 training examples (with ~80 potentially useful features), we don't want to remove any of these rows from the dataset. Let's instead focus on **imputation** techniques.\n",
    "\n",
    "We'll focus on columns that contain at least 1 missing value but less than 365 missing values (or 25% of the number of rows in the training set). There's no strict threshold, and **many people instead use a 50% cutoff** (if half the values in a column are missing, it's automatically dropped). Having some domain knowledge can help with determining an acceptable cutoff value.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- Select only the columns from train that contain more than 0 missing values but less than 584 missing values. Assign the resulting data frame to df_missing_values.\n",
    "- Display the number of missing values for each column in df_missing_values.\n",
    "- Display the data type for each column in df_missing_values.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Garage Type</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>Garage Finish</th>\n",
       "      <th>Garage Qual</th>\n",
       "      <th>Garage Cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.0</td>\n",
       "      <td>Stone</td>\n",
       "      <td>112.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>639.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>468.0</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>108.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>923.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>791.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lot Frontage Mas Vnr Type  Mas Vnr Area Bsmt Qual Bsmt Cond Bsmt Exposure  \\\n",
       "0         141.0        Stone         112.0        TA        Gd            Gd   \n",
       "1          80.0         None           0.0        TA        TA            No   \n",
       "2          81.0      BrkFace         108.0        TA        TA            No   \n",
       "3          93.0         None           0.0        TA        TA            No   \n",
       "4          74.0         None           0.0        Gd        TA            No   \n",
       "\n",
       "  BsmtFin Type 1  BsmtFin SF 1 BsmtFin Type 2  BsmtFin SF 2  Bsmt Unf SF  \\\n",
       "0            BLQ         639.0            Unf           0.0        441.0   \n",
       "1            Rec         468.0            LwQ         144.0        270.0   \n",
       "2            ALQ         923.0            Unf           0.0        406.0   \n",
       "3            ALQ        1065.0            Unf           0.0       1045.0   \n",
       "4            GLQ         791.0            Unf           0.0        137.0   \n",
       "\n",
       "   Total Bsmt SF  Bsmt Full Bath  Bsmt Half Bath Garage Type  Garage Yr Blt  \\\n",
       "0         1080.0             1.0             0.0      Attchd         1960.0   \n",
       "1          882.0             0.0             0.0      Attchd         1961.0   \n",
       "2         1329.0             0.0             0.0      Attchd         1958.0   \n",
       "3         2110.0             1.0             0.0      Attchd         1968.0   \n",
       "4          928.0             0.0             0.0      Attchd         1997.0   \n",
       "\n",
       "  Garage Finish Garage Qual Garage Cond  \n",
       "0           Fin          TA          TA  \n",
       "1           Unf          TA          TA  \n",
       "2           Unf          TA          TA  \n",
       "3           Fin          TA          TA  \n",
       "4           Fin          TA          TA  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_null_counts = train.isnull().sum()\n",
    "train_null_counts_subset = train_null_counts[(train_null_counts > 0) & (train_null_counts < 584)]\n",
    "train_null_counts_subset.index\n",
    "\n",
    "df_missing_values = train[train_null_counts_subset.index]\n",
    "df_missing_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Imputing Missing Values\n",
    "\n",
    "It looks like about half of the columns in `df_missing_values` are string columns (`object` data type), while about half are `float64` columns. For numerical columns with missing values, a common strategy is to compute the mean, median, or mode of each column and replace all missing values in that column with that value.\n",
    "\n",
    "Because imputation is a common task, pandas contains a method named `pandas.DataFrame.fillna()` that we can use for this. If we pass in a value, all of the missing values (`NaN`) in the data frame are replaced by that value.\n",
    "\n",
    "#### Instructions:\n",
    "- Impute the missing values from float_cols with the column's mean.\n",
    "- Check for any missing values in either string_cols or float_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(df_missing_values.shape[1]) # total features count\n",
    "print(df_missing_values.select_dtypes(['float']).shape[1]) # numerical features count\n",
    "print(df_missing_values.select_dtypes(['object']).shape[1]) # string features count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lot Frontage      0\n",
       "Mas Vnr Area      0\n",
       "BsmtFin SF 1      0\n",
       "BsmtFin SF 2      0\n",
       "Bsmt Unf SF       0\n",
       "Total Bsmt SF     0\n",
       "Bsmt Full Bath    0\n",
       "Bsmt Half Bath    0\n",
       "Garage Yr Blt     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select floats df\n",
    "float_cols = df_missing_values.select_dtypes(include=['float'])\n",
    "# prevent warning\n",
    "df_missing_values = df_missing_values.copy()\n",
    "# fill float NaNs with mean of columns (can also use np.mean)\n",
    "df_missing_values[float_cols.columns] = df_missing_values[float_cols.columns].fillna(df_missing_values.mean())\n",
    "# check float NaN counts\n",
    "df_missing_values[float_cols.columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Next Steps\n",
    "\n",
    "In this mission, we explored a few different techniques for transforming features into appropriate representations for a linear regression model. Next in this course is a guided project, where you'll practice the techniques you've learned in this course to build better linear regression models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
