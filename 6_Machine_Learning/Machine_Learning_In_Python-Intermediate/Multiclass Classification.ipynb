{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "### Learn how to use logistic regression with multiple categories.\n",
    "\n",
    "##### Contents:\n",
    "- Intro to the data    \n",
    "    - pandas.Series.unique()\n",
    "- Dummy variables\n",
    "    - pd.get_dummies()\n",
    "    - pd.concat()\n",
    "    - df.drop()\n",
    "- Multiclass classification\n",
    "    - one-versus-all method\n",
    "- Multiclass logistic regression model\n",
    "    - training\n",
    "        - string.startswith()\n",
    "    - testing\n",
    "        - model.predict_proba()\n",
    "\n",
    "## 1: Introduction To The Data\n",
    "\n",
    "The dataset we will be working with contains information on various cars. For each car we have information about the technical aspects of the vehicle such as the motor's displacement, the weight of the car, the miles per gallon, and how fast the car accelerates. Using this information we will predict the origin of the vehicle, either North America, Europe, or Asia. We can see, that unlike our previous classification datasets, we have three categories to choose from, making our task slightly more challenging.\n",
    "\n",
    "Here's a preview of the data:\n",
    "\n",
    "    18.0   8   307.0      130.0      3504.      12.0   70  1    \"chevrolet chevelle malibu\"\n",
    "    15.0   8   350.0      165.0      3693.      11.5   70  1    \"buick skylark 320\"\n",
    "    18.0   8   318.0      150.0      3436.      11.0   70  1    \"plymouth satellite\"\n",
    "    \n",
    "The dataset is hosted by the University of California Irvine on [their machine learning repository](https://archive.ics.uci.edu/ml/datasets/Auto+MPG). As a side note, the UCI Machine Learning repository contains many small datasets which are useful when getting your hands dirty with machine learning.\n",
    "\n",
    "You'll notice that the **Data Folder** contains a few different files. We'll be working with [auto-mpg.data](https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data), which omits the 8 rows containing missing values for fuel efficiency (`mpg` column). We've converted this data into a CSV file named `auto.csv` for you.\n",
    "\n",
    "Here are the columns in the dataset:\n",
    "\n",
    "- `mpg` -- Miles per gallon, Continuous.\n",
    "- `cylinders` -- Number of cylinders in the motor, Integer, Ordinal, and Categorical.\n",
    "- `displacement` -- Size of the motor, Continuous.\n",
    "- `horsepower` -- Horsepower produced, Continuous.\n",
    "- `weight` -- Weights of the car, Continuous.\n",
    "- `acceleration` -- Acceleration, Continuous.\n",
    "- `year` -- Year the car was built, Integer and Categorical.\n",
    "- `origin` -- Integer and Categorical. 1: North America, 2: Europe, 3: Asia.\n",
    "- `car_name` -- Name of the car.\n",
    "\n",
    "#### Instructions:\n",
    "- Import the Pandas library and read `auto.csv` into a Dataframe named cars.\n",
    "- Use the `Series.unique()` method to assign the unique elements in the column `origin` to `unique_regions`. Then use the `print` function to display `unique_regions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv('data/auto.csv')\n",
    "unique_regions = cars.origin.unique()\n",
    "unique_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Dummy Variables\n",
    "\n",
    "In previous classification missions, categorical variables have been represented in the dataset using integer values (like `0` and `1`) for us already. In many cases, like with this dataset, you'll have to create numeric representation of categorical values yourself. For this dataset, categorical variables exist in three columns, `cylinders`, `year`, and `origin`. The `cylinders` and `year` columns must be converted to numeric values so we can use them to predict label `origin`. Even though the column year is a number, weâ€™re going to treat them like categories. The year 71 is unlikely to relate to the year 70 in the same way those two numbers do numerically, but rather just as two different labels. In these instances, it is always safer to treat discrete values as categorical variables.\n",
    "\n",
    "We must use **dummy variables** for columns containing categorical values. Whenever we have more than 2 categories, we need to create more columns to represent the categories. Since we have 5 different categories of cylinders, we could use `3`, `4`, `5`, `6`, and `8` to represent the different categories. We can split the column into separate binary columns:\n",
    "\n",
    "- `cyl_3` -- Does the car have 3 cylinders? 0 if False, 1 if True.\n",
    "- `cyl_4` -- Does the car have 4 cylinders? 0 if False, 1 if True.\n",
    "- `cyl_5` -- Does the car have 5 cylinders? 0 if False, 1 if True.\n",
    "- `cyl_6` -- Does the car have 6 cylinders? 0 if False, 1 if True.\n",
    "- `cyl_8` -- Does the car have 8 cylinders? 0 if False, 1 if True.\n",
    "\n",
    "We can use the `pandas.get_dummies()` function to return a Dataframe containing binary columns from the values in the `cylinders` column. In addition, if we set the `prefix` parameter to `cyl`, Pandas will pre-pend the column names to match the style we'd like:\n",
    "\n",
    "    dummy_df = pd.get_dummies(cars[\"cylinders\"], prefix=\"cyl\")\n",
    "\n",
    "We then use the `pandas.concat()` function to add the columns from this Dataframe back to cars:\n",
    "\n",
    "    cars = pd.concat([cars, dummy_df], axis=1)\n",
    "\n",
    "Now it's your turn! Repeat the same process for the `year` column.\n",
    "\n",
    "#### Instructions:\n",
    "- Use the pandas.get_dummies() function to create dummy values from the year column.\n",
    "    - Use the prefix attribute to prepend year to each of the resulting column names.\n",
    "    - Assign the resulting Dataframe to dummy_years.\n",
    "- Use the pandas.concat() function to concatenate the columns from dummy_years to cars.\n",
    "- Use the DataFrame.drop() method to drop the year and cylinders columns from cars.\n",
    "- Display the first 5 rows of the new cars Dataframe to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70 71 72 73 74 75 76 77 78 79 80 81 82]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>origin</th>\n",
       "      <th>cyl_3</th>\n",
       "      <th>cyl_4</th>\n",
       "      <th>cyl_5</th>\n",
       "      <th>cyl_6</th>\n",
       "      <th>...</th>\n",
       "      <th>year_73</th>\n",
       "      <th>year_74</th>\n",
       "      <th>year_75</th>\n",
       "      <th>year_76</th>\n",
       "      <th>year_77</th>\n",
       "      <th>year_78</th>\n",
       "      <th>year_79</th>\n",
       "      <th>year_80</th>\n",
       "      <th>year_81</th>\n",
       "      <th>year_82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displacement  horsepower  weight  acceleration  origin  cyl_3  cyl_4  \\\n",
       "0  18.0         307.0       130.0  3504.0          12.0       1      0      0   \n",
       "1  15.0         350.0       165.0  3693.0          11.5       1      0      0   \n",
       "2  18.0         318.0       150.0  3436.0          11.0       1      0      0   \n",
       "3  16.0         304.0       150.0  3433.0          12.0       1      0      0   \n",
       "4  17.0         302.0       140.0  3449.0          10.5       1      0      0   \n",
       "\n",
       "   cyl_5  cyl_6   ...     year_73  year_74  year_75  year_76  year_77  \\\n",
       "0      0      0   ...           0        0        0        0        0   \n",
       "1      0      0   ...           0        0        0        0        0   \n",
       "2      0      0   ...           0        0        0        0        0   \n",
       "3      0      0   ...           0        0        0        0        0   \n",
       "4      0      0   ...           0        0        0        0        0   \n",
       "\n",
       "   year_78  year_79  year_80  year_81  year_82  \n",
       "0        0        0        0        0        0  \n",
       "1        0        0        0        0        0  \n",
       "2        0        0        0        0        0  \n",
       "3        0        0        0        0        0  \n",
       "4        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_cylinders = pd.get_dummies(cars[\"cylinders\"], prefix=\"cyl\")\n",
    "cars = pd.concat([cars, dummy_cylinders], axis=1)\n",
    "\n",
    "print(cars.year.unique())\n",
    "dummy_years = pd.get_dummies(cars.year, prefix=\"year\")\n",
    "\n",
    "cars = pd.concat([cars, dummy_years], axis=1)\n",
    "cars.drop('year',axis=1,inplace=True)\n",
    "cars.drop('cylinders',axis=1,inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Multiclass Classification\n",
    "\n",
    "In previous missions, we explored binary classification, where there were only 2 possible categories, or classes. When we have 3 or more categories, we call the problem a **multiclass classification** problem. There are a few different methods of doing multiclass classification and in this mission, we'll focus on the one-versus-all method.\n",
    "\n",
    "The one-versus-all method is a technique where we choose a single category as the Positive case and group the rest of the categories as the False case. We're essentially splitting the problem into multiple binary classification problems. For each observation, the model will then output the probability of belonging to each category.\n",
    "\n",
    "To start let's split our data into a training and test set. We've randomized the cars Dataframe for you already to start things off and assigned the shuffled Dataframe to `shuffled_cars`.\n",
    "\n",
    "#### Instructions:\n",
    "- Split the shuffled_cars Dataframe into 2 Dataframes: train and test.\n",
    "    - Assign the first 70% of the shuffled_cars to train.\n",
    "    - Assign the last 30% of the shuffled_cars to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_rows = np.random.permutation(cars.index)\n",
    "shuffled_cars = cars.iloc[shuffled_rows]\n",
    "\n",
    "highest_train_row = int(cars.shape[0] * .70)\n",
    "train = shuffled_cars.iloc[0:highest_train_row]\n",
    "test = shuffled_cars.iloc[highest_train_row:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Training A Multiclass Logistic Regression Model\n",
    "\n",
    "In the one-vs-all approach, we're essentially converting an n-class (in our case `n` is 3) classification problem into `n` binary classification problems. For our case, we'll need to train 3 models:\n",
    "\n",
    "- A model where all cars built in North America are considered Positive (1) and those built in Europe and Asia are considered Negative (0).\n",
    "- A model where all cars built in Europe are considered Positive (1) and those built in North America and Asia are considered Negative (0).\n",
    "- A model where all cars built in Asia are labeled Positive (1) and those built in North America and Europe are considered Negative (0).\n",
    "\n",
    "Each of these models is a binary classification model that will return a probability between 0 and 1. When we apply this model on new data, a probability value will be returned from each model (3 total). For each observation, we choose the label corresponding to the model that predicted the highest probability.\n",
    "\n",
    "We'll use the dummy variables we created from the `cylinders` and `year` columns to train 3 models using the LogisticRegression class from scikit-learn.\n",
    "\n",
    "#### Instructions: \n",
    "\n",
    "For each value in unique_origins, train a logistic regression model with the following parameters:\n",
    "\n",
    "- `X`: Dataframe containing just the cylinder & year binary columns.\n",
    "- `y`: list (or Series) of Boolean values:\n",
    "    - `True` if observation's value for origin matches the current iterator variable.\n",
    "    - `False` if observation's value for origin doesn't match the current iterator variable.\n",
    "\n",
    "Add each model to the models dictionary with the following structure:\n",
    "\n",
    "- key: origin value (1, 2, or 3),\n",
    "- value: relevant LogistcRegression model instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "unique_origins = cars[\"origin\"].unique()\n",
    "unique_origins.sort()\n",
    "\n",
    "models = {}\n",
    "features = [c for c in train.columns if c.startswith(\"cyl\") or c.startswith(\"year\")]\n",
    "\n",
    "for origin in unique_origins:\n",
    "    model = LogisticRegression()\n",
    "    X_train = train[features]\n",
    "    y_train = train.origin == origin\n",
    "    model.fit(X_train, y_train)\n",
    "    models[origin] = model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Testing The Models\n",
    "\n",
    "Now that we have a model for each category, we can run our test dataset through the models and evaluate how well they performed.\n",
    "\n",
    "#### Instructions:\n",
    "- For each origin value from unique_origins:\n",
    "    - Use the LogisticRegression predict_proba function to return the 3 lists of predicted probabilities for the test set and add to the testing_probs Dataframe.\n",
    "- Here's how the final Dataframe should look like (without all zeroes of course!):\n",
    "\n",
    "|   | 1     | 2     | 3     |\n",
    "|---|-------|-------|-------|\n",
    "| 0 | 0.000 | 0.000 | 0.000 |\n",
    "| 1 | 0.000 | 0.000 | 0.000 |\n",
    "| 2 | 0.000 | 0.000 | 0.000 |\n",
    "| 3 | 0.000 | 0.000 | 0.000 |\n",
    "| 4 | 0.000 | 0.000 | 0.000 |\n",
    "| 5 | 0.000 | 0.000 | 0.000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.968470</td>\n",
       "      <td>0.030118</td>\n",
       "      <td>0.022281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955135</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>0.073064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.960664</td>\n",
       "      <td>0.022932</td>\n",
       "      <td>0.038702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.868371</td>\n",
       "      <td>0.083001</td>\n",
       "      <td>0.059900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.325527</td>\n",
       "      <td>0.318606</td>\n",
       "      <td>0.345816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3\n",
       "0  0.968470  0.030118  0.022281\n",
       "1  0.955135  0.016504  0.073064\n",
       "2  0.960664  0.022932  0.038702\n",
       "3  0.868371  0.083001  0.059900\n",
       "4  0.325527  0.318606  0.345816"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_probs = pd.DataFrame(columns=unique_origins)\n",
    "\n",
    "for origin in unique_origins:\n",
    "    testing_probs[origin] = models[origin].predict_proba(test[features])[:,1]\n",
    "    \n",
    "testing_probs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Choose The Origin\n",
    "\n",
    "Now that we trained the models and computed the probabilities in each origin we can classify each observation. To classify each observation we want to select the origin with the highest probability of classification for that observation.\n",
    "\n",
    "While each column in our dataframe `testing_probs` represents an origin we just need to choose the one with the largest probability. We can use the [Dataframe method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.idxmax.html) `.idxmax()` to return a Series where each value corresponds to the column or where the maximum value occurs for that observation. We need to make sure to set the `axis` paramater to `1` since we want to calculate the maximum value across columns. Since each column maps directly to an origin the resulting Series will be the classification from our model.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- Classify each observation in the test set using the `testing_probs` Dataframe.\n",
    "- Assign the predicted origins to `predicted_origins` and use the `print` function to display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      3\n",
      "5      1\n",
      "6      3\n",
      "7      1\n",
      "8      2\n",
      "9      2\n",
      "10     1\n",
      "11     2\n",
      "12     2\n",
      "13     1\n",
      "14     2\n",
      "15     3\n",
      "16     1\n",
      "17     1\n",
      "18     1\n",
      "19     1\n",
      "20     2\n",
      "21     3\n",
      "22     1\n",
      "23     2\n",
      "24     1\n",
      "25     1\n",
      "26     2\n",
      "27     1\n",
      "28     2\n",
      "29     2\n",
      "      ..\n",
      "88     3\n",
      "89     1\n",
      "90     1\n",
      "91     3\n",
      "92     1\n",
      "93     2\n",
      "94     1\n",
      "95     1\n",
      "96     1\n",
      "97     1\n",
      "98     1\n",
      "99     1\n",
      "100    3\n",
      "101    1\n",
      "102    1\n",
      "103    1\n",
      "104    1\n",
      "105    1\n",
      "106    1\n",
      "107    1\n",
      "108    1\n",
      "109    1\n",
      "110    1\n",
      "111    1\n",
      "112    2\n",
      "113    1\n",
      "114    1\n",
      "115    1\n",
      "116    1\n",
      "117    1\n",
      "Length: 118, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predicted_origins = testing_probs.idxmax(axis=1)\n",
    "print(predicted_origins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Conclusion\n",
    "\n",
    "In this mission, we learned the basics of extending logistic regression to work for multi-class classification problems. In the next mission, we'll dive into more intermediate linear regression concepts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
