{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation\n",
    "### Learn how to use k-fold cross validation to perform more rigorous testing.\n",
    "\n",
    "#### Contents:\n",
    "- Partitioning data with np.random.permutation()\n",
    "- Creating function to iterate through folds\n",
    "- sklearn.cross_validation.KFold\n",
    "- sklearn.cross_validation.cross_val_score\n",
    "\n",
    "## 1: K Fold Cross Validation\n",
    "\n",
    "In the previous mission, we learned about cross validation, a technique for testing a machine learning model's accuracy on new data that the model wasn't trained on. Specifically, we focused on the **holdout validation** technique, which involved:\n",
    "\n",
    "- splitting the full dataset into 2 partitions:\n",
    "    - a training set and\n",
    "    - a test set\n",
    "- training the model on the training set,\n",
    "- using the trained model to predict labels on the test set,\n",
    "- computing an error metric (e.g. simple accuracy) to understand the model's accuracy.\n",
    "\n",
    "Holdout validation is actually a specific example of a larger class of validation techniques called **k-fold cross-validation**. K-fold cross-validation works by:\n",
    "\n",
    "- splitting the full dataset into k equal length partitions,\n",
    "    - selecting k-1 partitions as the training set and\n",
    "    - selecting the remaining partition as the test set\n",
    "- training the model on the training set,\n",
    "- using the trained model to predict labels on the test set,\n",
    "- computing an error metric (e.g. simple accuracy) and setting aside the value for later,\n",
    "- repeating all of the above steps k-1 times, until each partition has been used as the test set for an iteration,\n",
    "- calculating the mean of the k error values.\n",
    "\n",
    "Using 5 or 10 folds is common for k-fold cross-validation. Here's a diagram describing each iteration of 5-fold cross validation:\n",
    "\n",
    "<img src=\"http://i.imgur.com/gu3Fa6w.png\">\n",
    "\n",
    "Since you're training k models, the more number of folds you use the longer it takes. When working with large datasets, often only a few number of folds are used because of the time and cost it takes, with the tradeoff that having more training examples helps improve the accuracy even with less folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Partititioning The Data\n",
    "\n",
    "To explore k-fold cross-validation, we'll continue to work with the dataset on graduate admissions. Recall that this dataset contains data on 644 applications with the following columns:\n",
    "\n",
    "- `gre` - applicant's store on the Graduate Record Exam, a generalized test for prospective graduate students.\n",
    "    - Score ranges from 200 to 800.\n",
    "- `gpa` - college grade point average.\n",
    "    - Continuous between 0.0 and 4.0.\n",
    "- `admit` - binary value\n",
    "    - Binary value, 0 or 1, where 1 means the applicant was admitted to the program and 0 means the applicant was rejected.\n",
    "\n",
    "To save you time, we've already imported the Pandas library, read in admissions.csv into a Dataframe, renamed the admit column to actual_label, and randomized the ordering of the rows.\n",
    "\n",
    "Now, partition the dataset into 5 folds.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "Partition the dataset into 5 folds and store each row's fold in a new integer column named fold:\n",
    "\n",
    "- Fold 1 : rows from index 0 to 128, including both of those rows.\n",
    "- Fold 2 : rows from index 129 to 257, including both of those rows.\n",
    "- Fold 3 : rows from index 258 to 386, including both of those rows.\n",
    "- Fold 4 : rows from index 387 to 514, including both of those rows.\n",
    "- Fold 5 : rows from index 515 to the last row, including both of those rows.\n",
    "\n",
    "Display the first 5 rows and the last 5 rows of the Dataframe to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "admissions = pd.read_csv(\"data/admissions.csv\")\n",
    "admissions[\"actual_label\"] = admissions[\"admit\"]\n",
    "admissions = admissions.drop(\"admit\", axis=1)\n",
    "\n",
    "shuffled_index = np.random.permutation(admissions.index)\n",
    "shuffled_admissions = admissions.loc[shuffled_index]\n",
    "admissions = shuffled_admissions.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602</td>\n",
       "      <td>3.065215</td>\n",
       "      <td>674.458792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349</td>\n",
       "      <td>3.202372</td>\n",
       "      <td>481.429935</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>2.948845</td>\n",
       "      <td>683.353304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291</td>\n",
       "      <td>3.183651</td>\n",
       "      <td>675.172488</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>455</td>\n",
       "      <td>3.533454</td>\n",
       "      <td>633.328152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       gpa         gre  actual_label  fold\n",
       "0    602  3.065215  674.458792             1     1\n",
       "1    349  3.202372  481.429935             0     1\n",
       "2    632  2.948845  683.353304             1     1\n",
       "3    291  3.183651  675.172488             0     1\n",
       "4    455  3.533454  633.328152             1     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[row_indexer,column_indexer] (multi-axis indexing)\n",
    "\n",
    "admissions.loc[0:128, \"fold\"] = 1\n",
    "admissions.loc[129:257, \"fold\"] = 2\n",
    "admissions.loc[258:386, \"fold\"] = 3\n",
    "admissions.loc[387:514, \"fold\"] = 4\n",
    "admissions.loc[515:, \"fold\"] = 5\n",
    "# Ensure the column is set to integer type.\n",
    "admissions[\"fold\"] = admissions[\"fold\"].astype('int')\n",
    "\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>99</td>\n",
       "      <td>2.916654</td>\n",
       "      <td>661.170680</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>69</td>\n",
       "      <td>2.961642</td>\n",
       "      <td>641.397957</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>574</td>\n",
       "      <td>3.673019</td>\n",
       "      <td>649.650931</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>59</td>\n",
       "      <td>2.953116</td>\n",
       "      <td>590.745298</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>278</td>\n",
       "      <td>3.540320</td>\n",
       "      <td>555.027864</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       gpa         gre  actual_label  fold\n",
       "639     99  2.916654  661.170680             0     5\n",
       "640     69  2.961642  641.397957             0     5\n",
       "641    574  3.673019  649.650931             1     5\n",
       "642     59  2.953116  590.745298             0     5\n",
       "643    278  3.540320  555.027864             0     5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: First Iteration\n",
    "\n",
    "In the first iteration, let's assign fold 1 as the test set and folds 2 to 5 as the training set. Then, train the model and use it to predict labels for the test set.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- Train a logistic regression model using the gpa column as the sole feature from folds 2 to 5 as the training set.c\n",
    "- Use the model to make predictions on the test set and assign the predicted labels to labels.\n",
    "- Calculate the accuracy by comparing the predicted labels with the actual labels from the actual_label column on the test set.\n",
    "- Assign the accuracy value to iteration_one_accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651162790698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "train = admissions[admissions['fold'] != 1]\n",
    "test = admissions[admissions['fold'] == 1]\n",
    "\n",
    "model.fit(train[['gpa']],train['actual_label'])\n",
    "labels = model.predict(test[['gpa']])\n",
    "\n",
    "test = test.copy() # to prevent warning\n",
    "test['predicted_label'] = labels\n",
    "test['matches'] = test.predicted_label == test.actual_label\n",
    "\n",
    "iteration_one_accuracy = sum(test.matches) / test.shape[0]\n",
    "print(iteration_one_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Function For Training Models\n",
    "\n",
    "From the first iteration, we achieved an accuracy score of **60.5%** accuracy. Let's now run through the rest of the iterations to see how the accuracy changes after each iteration and to compute the mean accuracy.\n",
    "\n",
    "To make the iteration process easier, wrap the code you in the previous screen in a function.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- Write a function named train_and_test that takes in a Dataframe and a list of fold id values (1 to 5 in our case) and returns a list of accuracy values, e.g.:\n",
    "\n",
    "\n",
    "`[0.5, 0.5, 0.5, 0.5, 0.5]`\n",
    "    \n",
    "- Use the train_and_test function to return the list of accuracy values for the admissions Dataframe and assign to accuracies. e.g.:\n",
    "\n",
    "`accuracies = train_and_test(admissions, [1,2,3,4,5])`\n",
    "    \n",
    "- Compute the average accuracy and assign to average_accuracy.\n",
    "- average_accuracy should be a float value while accuracies should be a list of float values (one float value per iteration).\n",
    "- Use the variable inspector or the print function to display the values for accuracies and average_accuracy.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test(df, fold_ids):\n",
    "    accuracies = []\n",
    "    for i in fold_ids:\n",
    "        train = df[df['fold'] != i]\n",
    "        test = df[df['fold'] == i]\n",
    "        \n",
    "        model.fit(train[['gpa']],train['actual_label'])\n",
    "        labels = model.predict(test[['gpa']])\n",
    "\n",
    "        test = test.copy() # to prevent warning\n",
    "        test['predicted_label'] = labels\n",
    "        test['matches'] = test.predicted_label == test.actual_label\n",
    "\n",
    "        accuracy = sum(test.matches) / test.shape[0]\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65116279069767447, 0.62015503875968991, 0.69767441860465118, 0.640625, 0.61240310077519378] 0.644404069767\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fold_ids = [1,2,3,4,5]\n",
    "accuracies = train_and_test(admissions, fold_ids)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(accuracies, average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Sklearn\n",
    "\n",
    "The average accuracy value was **64.8%**, compared to an accuracy value of **63.6%** using holdout validation from the last mission. In many cases, the resulting accuracy values don't differ much between a simpler, less time-intensive method like holdout validation and a more robust but more time-intensive method like k-fold cross-validation. As you use these and other cross validation techniques more often, you should get a better sense of these tradeoffs and when to use which validation technique.\n",
    "\n",
    "In addition, the computed accuracy values for each fold stayed within 61% and 63%, which is a healthy sign. Wild variations in the accuracy values between folds is usually indicative of using too many folds (k value). By implementing your own k-fold cross-validation function, you hopefully acquired a good understanding of the inner workings of the technique.\n",
    "\n",
    "When working in a production environment however, you should use scikit-learn. Scikit-learn has a few different tools that make performing cross validation easy. Similar to having to instantiate a LinearRegression or LogisticRegression object before you can train one of those models, you need to instantiate a [KFold class](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) before you can perform k-fold cross-validation:\n",
    "\n",
    "    kf = KFold(n, n_folds, shuffle=False, random_state=None)\n",
    "\n",
    "where:\n",
    "\n",
    "- `n` is the number of observations in the dataset,\n",
    "- `n_folds` is the number of folds you want to use,\n",
    "- `shuffle` is used to toggle shuffling of the ordering of the observations in the dataset,\n",
    "- `random_state` is used to specify a seed value if shuffle is set to True.\n",
    "\n",
    "You'll notice here that only the first parameter depends on the dataset at all. This is because the KFold class returns an iterator object but won't actually handle the training and testing of models. If we're primarily only interested in accuracy and error metrics for each fold, we can use the KFold class in conjunction with the [cross_val_score function](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html), which will handle training and testing of the models in each fold.\n",
    "\n",
    "Here are the relevant parameters for the `cross_val_score` function:\n",
    "\n",
    "    cross_val_score(estimator, X, Y, scoring=None, cv=None)\n",
    "    \n",
    "where:\n",
    "\n",
    "- `estimator` is a sklearn model that implements the fit method (e.g. instance of LinearRegression or LogisticRegression),\n",
    "- `X` is the list or 2D array containing the features you want to train on,\n",
    "- `y` is a list containing the values you want to predict (target column),\n",
    "- `scoring` is a string describing the scoring criteria (list of accepted values [here](http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values)).\n",
    "- `cv` describes the number of folds. Here are some examples of accepted values:\n",
    "    - an instance of the `KFold` class,\n",
    "    - an integer representing the number of folds.\n",
    "\n",
    "Depending on the scoring criteria you specify, either a single value is returned (e.g. `average_precision`) or an array of values (e.g. `accuracy`), one value for each fold.\n",
    "\n",
    "Here's the general workflow for performing k-fold cross-validation using the classes we just described:\n",
    "\n",
    "- instantiate the model class you want to fit (e.g. LogisticRegression),\n",
    "- instantiate the `KFold` class and using the parameters to specify the k-fold cross-validation attributes you want,\n",
    "- use the `cross_val_score` function to return the scoring metric you're interested in.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Sklearn\n",
    "\n",
    "#### Instructions:\n",
    "- Create a new instance of the KFold class with the following properties:\n",
    "    - n set to length of admissions,\n",
    "    - 5 folds,\n",
    "    - shuffle set to True,\n",
    "    - random seed set to 8 (so we can answer check using the same seed),\n",
    "    - assigned to the variable kf.\n",
    "- Create a new instance of the LogisticRegression class and assign to lr.\n",
    "- Use the cross_val_score function to perform k-fold cross-validation:\n",
    "    - using the LogisticRegression instance lr,\n",
    "    - using the gpa column for training,\n",
    "    - using the actual_label column as the target column,\n",
    "    - returning an array of accuracy values (one value for each fold).\n",
    "- Assign the resulting array of accuracy values to accuracies, compute the average accuracy, and assign the average to average_accuracy.\n",
    "- Use the variable inspector or the print function to display the values for accuracies and average_accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "admissions = pd.read_csv(\"data/admissions.csv\")\n",
    "admissions[\"actual_label\"] = admissions[\"admit\"]\n",
    "admissions = admissions.drop(\"admit\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6124031   0.65891473  0.64341085  0.6744186   0.6328125 ] 0.644391957364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kf = KFold(n=len(admissions), n_folds=5, shuffle=True, random_state=8)\n",
    "\n",
    "accuracies = cross_val_score(estimator=lr, X=admissions[['gpa']], y=admissions.actual_label, cv=kf)\n",
    "\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(accuracies, average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Interpretation\n",
    "\n",
    "Using 5-fold cross-validation, we achieved an average accuracy score of **64.4%**, which closely matches the **63.6%** accuracy score we achieved using holdout validation. When working with simple univariate models, often holdout validation is more than enough and the similar accuracy scores confirm this. When you're using multiple features to train a model (multivariate models), performing k-fold cross-validation can give you a better sense of the accuracy you should expect when you use the model on data it wasn't trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8: Next Steps\n",
    "\n",
    "In this mission, we explored a more robust cross validation technique called k-fold cross-validation. Cross-validation helps us understand a model's generalizability and reduce overfitting. In the next mission, we'll explore some more specific overfitting techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
