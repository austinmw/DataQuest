Please enter your information and your polling organization's information. We won't publish your pollster ID, phone number and email address.		"Since <a href=""http://fivethirtyeight.com/tag/poll-of-pollsters/"" target=""_blank"">we last did</a> a poll of pollsters -- after <a href=""http://fivethirtyeight.com/features/the-polls-were-skewed-toward-democrats/"" target=""_blank"">many polls missed</a> last November’s Republican wave -- we’ve had a number of polling misses, mostly outside the U.S.: <a href=""http://fivethirtyeight.com/features/how-israels-exit-pollsters-missed-right-wing-rally-for-netanyahu/"" target=""_blank"">Israel</a>, the <a href=""http://fivethirtyeight.com/datalab/what-we-got-wrong-in-our-2015-uk-general-election-model/"" target=""_blank"">U.K.</a>, <a href=""http://fivethirtyeight.com/datalab/the-polls-were-bad-in-greece-the-conventional-wisdom-was-worse/"" target=""_blank"">Greece</a> and <a href=""http://fivethirtyeight.com/features/what-to-make-of-kentuckys-polling-failure/"" target=""_blank"">Kentucky</a>. Is the U.S. polling industry in better or worse shape than a year ago?"		Given the decline in response rates to telephone polls, are you surprised that telephone polls haven’t missed election results by even more than they have?		Has it gotten easier or harder to get responses from voters since your polling of the 2014 election?		What is your average response rate in polling for the 2016 election, in percentage points? (Please enter a number between 0 and 100; decimals are OK.)	What was your average response rate in polling for the 2014 election, in percentage points? (Please enter a number between 0 and 100; decimals are OK.)	How are you defining response rate?	Do you think pollsters’ public image has improved or declined since the 2012 election?		"In <a href=""http://www.newyorker.com/magazine/2015/11/16/politics-and-the-new-machine"" target=""_blank"">her recent New Yorker feature on polling</a>, Jill Lepore wrote sympathetically about Lindsay Rogers’s contention that polls “are a majoritarian monstrosity.” What is your response to that?"	What are the toughest states to poll during primaries? (Enter up to five states)					Why?	Has polling during the primaries, and coverage of it, helped or hurt the industry’s reputation?		"<a href=""http://www.politico.com/story/2015/12/jeb-bush-donors-polls-216436"" target=""_blank"">Jeb Bush</a> and <a href=""http://fivethirtyeight.com/features/dear-media-stop-freaking-out-about-donald-trumps-polls/"" target=""_blank"">Nate Silver</a> are saying to ignore national primary polls before the election has started. Do you agree?"		"Is it fair to use national primary polls in <a href=""http://fivethirtyeight.com/features/theres-no-perfect-way-to-sort-the-candidates-for-a-primary-debate/"" target=""_blank"">determining</a> who gets to appear in the main televised debates and the undercards?"		"Should voters and the media be paying any attention to <a href=""http://fivethirtyeight.com/features/a-year-out-ignore-general-election-polls/"" target=""_blank"">general election polls</a> conducted the year before the election?"		If not, is there any value in conducting general-election polls now?		"Live-interviewer polls <a href=""http://www.huffingtonpost.com/entry/republicans-donald-trump-support_55fc060de4b00310edf699a9"" target=""_blank"">consistently have found lower support</a> for Donald Trump than interactive voice response (IVR) and online polls. Which set of polls do you think is closer to correct?"		"Does the future of polling <a href=""http://fivethirtyeight.com/features/the-future-of-polling-may-depend-on-donald-trumps-fate/"" target=""_blank"">depend on Donald Trump’s fate</a>?"		"Do you think placing <a href=""http://www.usnews.com/opinion/blogs/lara-brown/2015/12/04/the-cnn-poll-with-trump-at-36-percent-has-a-serious-flaw"" target=""_blank"">questions about immigration</a> in a survey questionnaire before candidate-preference questions can bias respondents toward Donald Trump?"		"Do you think Donald Trump's <a href=""http://www.nytimes.com/2015/08/02/us/politics/republican-debate-donald-trump.html"" target=""_blank"">boast about not having a pollster</a> helps or hurts him with voters overall?"		"Polls this year of Muslim sentiment in <a href=""http://bridge.georgetown.edu/new-poll-on-american-muslims-is-grounded-in-bias-riddled-with-flaws/"" target=""_blank"">the U.S.</a> and <a href=""http://www.theguardian.com/media/2015/nov/23/sun-poll-respondents-found-using-list-of-muslim-surnames"" target=""_blank"">the U.K.</a> have been criticized for being deeply flawed in ways that could have biased the results. Do you have any plans to poll American Muslims?"		"How meaningful are general religion categories like ""Catholic"" given how much opinions and habits can vary within those categories?"	"Is <a href=""http://www.politico.com/story/2015/10/gallup-poll-2016-pollsters-214493"" target=""_blank"">Gallup’s exit from horse-race polling</a> good or bad for the polling industry?"		"Many stories about Gallup’s exit, including <a href=""http://fivethirtyeight.com/datalab/gallup-gave-up-heres-why-that-sucks/"" target=""_blank"">ours</a>, said the company’s name is “synonymous” with polling. Is there a new brand name in the industry that should be equated with polling?"		"The Los Angeles Times <a href=""http://www.latimes.com/politics/la-na-why-an-online-poll-html-20151108-htmlstory.html"" target=""_blank"">is partnering with SurveyMonkey</a>. Do you think SurveyMonkey’s polling methods are good enough for a prominent media partner to use?"		Do prediction markets provide a more accurate picture of who are the leading contenders for the presidential nomination at this stage of the race than polls do?		How well are polling aggregator websites filtering out polls from bad polling organizations?		Are there polling firms whose polls you've seen included by polling aggregators that you think shouldn't be?		Who do you expect will be the Democratic nominee for president in the 2016 election?		Who do you expect will be the Republican nominee for president in the 2016 election?		How many seats do you expect Republicans will hold in the Senate in 2017 -- after the 2016 election? (They currently hold 54.)	How many seats do you expect Republicans will control in the House in 2017 -- after the 2016 election? (They currently hold 246.)	What question or questions would you want us to ask your fellow pollsters in future rounds of this poll?
Respondent Name	Polling Organization	Response	Please explain your answer:	Response	Please explain your answer:	Response	Please explain your answer:	Open-Ended Response	Open-Ended Response	Open-Ended Response	Response	Please explain your answer:	Open-Ended Response	State 1	State 2	State 3	State 4	State 5	Open-Ended Response	Response	Please explain your answer:	Response	Please explain your answer:	Response	Please explain your answer. And if you’d rather polls not be used in this way, what alternative method would you suggest?	Response	Please explain your answer:	Response	Please explain your answer:	Response	Please explain your answer:	Response	Please explain your answer:	Response	Please explain your answer:	Response	Please explain your answer:	Response	Please explain your answer. And if you answered yes, how would you poll American Muslims in a way that would provide fair, representative results?	Open-Ended Response	Response	Please explain your answer:	Response	If you answered yes, which brand name should it be?	Response	Please explain your answer:	Response	Please explain your answer:	Response	Please explain your answer:	Response	If you answered yes, please name them here:	Response	Other (please specify)	Response	Other (please specify)	Open-Ended Response	Open-Ended Response	Open-Ended Response
John Anzalone	Anzalone Liszt Grove Research																																																										
Micheline Blum	Blum & Weprin Associates	Better	 Better for those who use the best methodology. Sometimes, we adjust for the last election -- but it's the wrong election. In 2012, some were looking at 2010 instead of 2008, and in 2014 many adjusted for their 2012 Republican bias. We underestimate the enormous difference in the electorate in presidential and non-presidential years. I am hoping we have learned from 2012 and 2014 and will do better in 2016.	Yes	It used to surprise me, but after a steady decline and and the many polls and studies showing that it was still possible to be on target, I am gratified that probability sampling of land and cell, careful household selection, the judicious use of likely voter screens, and the use of well trained live interviewers has limited the effect of low response.						Declined	Because most people don't know the differences in methodology, good and bad polls are lumped together.	Polls are a reflection of the views of the populace -- majority and minority. They are of enormous value and a public service to everyone. The reporting of polls and the response to the polls may occasionally overemphasize the views of the majority, but that does not diminish the value of the polls themselves.	New Hampshire					Independent voters can vote in either primary. 	Helped	It has helped boost interest in the election.	No	They are not helpful for predictions, but they tell us something about the mood of the country.	Yes	Otherwise 2 states determine whom we all get to hear.	No		Yes	To define the issues.	Live-interviewer polls	"My leaning is toward live-interviewer polls, but we don't know yet. I am guessing that there may be some ""convergence"" in the last weeks."	No	But we may learn from it.	Yes	No substantive questions should precede candidate preference.	Helps	Some may think it means he does not follow public opinion and makes up his own mind. But it is clear that he pays close attention to public polls.	No		It can be meaningful, but religion is often not as meaningful as religiosity.	Neither		No																
Bernie Porn	EPIC-MRA																																																										
Krista Jenkins	Fairleigh Dickinson University (PublicMind)										Not sure	Accuracy rarely makes the news, whereas misses make headlines.	It depends on how they are used and interpreted.							Not sure	I think it remains to be seen. It depends on how things shake out when folks start to vote in a few weeks. If anything, I see the media as bearing the brunt of public ire as people grow increasingly tired of breathless stories about polls, with little substantive discussion of the candidates.	No	I don't think they should be ignored completely, as they reveal interesting trends in the aggregate. It's their misuse as indicators of real voter sentiment that troubles me.	No	Others have argued this far better than I. Kudos, for example, go to Marist for consistency in their action and words. A decision to reject the use of national polls for debate inclusion was followed by consistent behavior.	No	Is any explanation really necessary?	Yes	Again, they reveal trends and insight into early indicators of possible success, but nothing more.	Neither	I simply don't know, and don't wish to speculate. A reasonable rationale could be crafted in either direction.	No	Polling has been around a very long time and is strong enough to endure even The Donald.	Yes	See the spate of research on question order effects.	Neither	Who knows?	No		True, there's some slippage, but there remains value in knowing how folks categorize themselves in regard to religiosity.	Good	They have been and continue to be industry leaders.	Yes	Pew Research Center															
Mark DiCamillo	Field Research Corporation (Field Poll)	Worse	Too many polls are now of dubious methodological quality.	No	Declining response rates are not in an of themselves the problem. Differential non-response is. Well conducted polls can still take steps to reduce differential non-response.														We only poll in California.	Hurt	It's certainly more difficult to poll voters in primaries than general elections, given the much greater variability in composition of their electorates from year to year.	No	While they can not be used as forecasts well-conducted ones do give us new information about how voters nationally are reacting to campaign events.	No	There are no statistically significant differences between many of the lower tier candidates in these polls. Simply leave it to the judgment of the debate sponsors.	No	Not much	Not sure	They don't have much real value although they do document the ebb and flow of campaign events.	Live-interviewer polls	Until we know more about the methodological accuracy of non-probability polls, better to trust the live interviewer polls.	No	Silly question	Yes	The placement of any questions in advance of the trial-heat question is potentially biasing.	Helps	It makes him appear more genuine and less programmed.				Bad	They are still among the better polling organizations and the absence of the better polling firms from the pre-election will mean they will be replaced by others many of which are of low quality.	No																
Nick Gourevitch	Global Strategy Group	About the same	On the one hand, there are increasing challenges in the polling industry that are frequently written about and reported on (declining response rates, increasing cell-only households, etc.). On the other hand, pollsters -- especially in the world of private campaign polling -- have access to incredible data and technology that we simply did not have access to ten years ago. We have voters with deep individual level data that contain predictive models and analytics that are improved with each election cylce. So these two things are pulling the industry in opposite directions -- it's harder to reach people but we know more about the people we're trying to reach. So while it can be easy to be pessimistic about low response rates, there's also reason to be optimistic about the amount of data, technology, and analytics available to pollsters these days. This has certainly made the job more complex and challenging than it has been in the past -- but there's still reason for optimism. 	No	"I'm not incredibly surprised they haven't been bigger. I will say that I would encourage outside observers to the polling industry to consider the many reasons why a poll might be ""wrong"" other than a decline in response rates. While response rates are certainly part of it, they are not the only reason why something might be wrong. It's possible that an electorate was modeled or weighted incorrectly. It's possible that the race shifted and voter preferences changed after the poll was conducted. There are other explanations as well. In sum, a poll done methodologically correctly can look ""wrong."" And a poll done using a terrible methodology can look ""right."" I don't want to downplay response rates because it's a big factor and a huge challenge for the industry, but the debate of right vs. wrong is more than just about response rates."	Harder	Things seem to get slightly harder each year. For example, our 2015 general election work was generally harder and required more dialing hours than similar 2013 work. As we prepare for 2016, we expect that they younger skew of the presidential electorate will present deeper challenges than we had in 2012.				Declined		That criticism conflates the value of polling with the way some people choose to use polling. Polling can be misused just like any other scientific tool. Take a look through the amazing data that Pew Research puts together on a regular basis and tell me that what they provide is not a great public service. And in the private realm, it's hard to argue that an elected official shouldn't know and understand how their constituents think on certain issues. It's how those questions are framed and how the answers are used that matter.									No	Ignoring is too far -- early polls tell us something, they just don't tell us anything all that predictive. But they do tell us how the public is experiencing and reacting to the campaign. They obviously don't tell us who is going to win any individual states and they aren't predictive of who will win the nomination.	No	Because they are not predictive, this seems like a silly criteria. Maybe the parties need a selection committee like they have in March Madness that weight a series of criteria that includes polling, organization, fundraising, etc. I'm sure that has it's flaws as well, but no single factor feels like it should determine inclusion.	No		Yes	I think general election polls this far out are still valuable in understand the atmospherics leading up to the election -- evaluating things like name recognition, issue priorities, etc. This question seems to imply that the only reason to conduct a poll is to predict who might win -- that's not the only reason people do polls.																Yes	I think that new entries into the polling ecosystem will only make everyone better. I would welcome them -- and anyone else who is legitimately trying to improve the industry -- into the fold.	Not sure		Well										
Doug Kaplan	Gravis Marketing	About the same		No		About the same					Neither		Public opinion polls are not a crystal ball to look into the future. They mention public opinion at the current time they are conducted. People want to have an idea on where the public stands on issues.	Nevada	Arizona	New Mexico						No	The national polls are early indicators of trends that can be happening in early primary states. Example: Ben Carson dropped nationally and we saw that trend later in Iowa.	Yes	The mixture CNN worked using national and early states was the best way to do it.	No	If you use 2016 as an example, the Republicans are going to perform better against Hillary Clinton when polls are conducted one year before the election because of the amount of coverage they are receiving and the GOP has much more of a competitive primary than the Democrats. When we have an idea of who the nominee will be, it is reasonable to pay attention to the general election polls to have an idea on where the country stands nationally and in battleground states.	Yes		IVR and online polls	Depends on the type of data that is used. Random digit dialing or voter file.	No	Mr. Trump is an abnormality. It is hard to compare him to anyone that has run previously for a major party nomination. Silvio Berlusconi would be the closest comparison.	Not sure	We generally place issues questions after the candidate question or we rotate it 50% before and 50% after.	Neither	This would be the last thing voters care about.	Yes	This is something we are currently working on. We would use the Gravis consumer file. We would ask the questions in a way that is not specifically targeted to Muslims.	Very important. Church attendance is another important question we have started to ask.	Neither	They are a great organization. Many great polling firms still exist.	No	Many great polling firms	Yes		No		Not sure		No	As long as the polls are being conducted without an agenda then they should be counted.	Hillary Clinton		Marco Rubio		49	225	
Benjamin Margolis	Hickman Analytics																																																										
Julia Clark	Ipsos	About the same	I think that our industry here in the US is changing (Gallup dropping out; more online pollsters paired with major media partners) but i don't think that means the industry is in better or worse shape. It is simply evolving.	No	"I don't believe that methodology alone is a predictor of accuracy in polling at all any more, nor has it been for awhile; the 2012 election proved that when Gallup (phone) did poorly and PPP/Ipsos did well (IVR/online). I think that election accuracy is dependent on the team overseeing the work, and their expertise, regardless of institution or methodology. The dramatic decline of phone response rates over the past 20 years now means that saying ""phone polls are more accurate"" or ""online polls are more accurate"" is simplistic and almost irrelevant. We are all working with the best methods we can and optimizing towards the same outcome: accurate election measurement and prediction."	About the same	Very little has changed; it has only been a year. Panel maintenance for online polls is increasingly challenging, but we use a lot of river sample, which helps counterbalance this.			We don't calculate response rates; our online surveys utilize a continual flow of river sample so the outgoing sample is not finite.	Neither	"I think that the public's image of pollsters is low to begin with, but probably relatively stable. We're not high on their radars in general, so why would views change notably? In the UK, for example, it has been pretty stable with a few ""blips"": https://www.ipsos-mori.com/researchpublications/researcharchive/15/Trust-in-Professions.aspx "	"It was a wonderful article! I'd point out that a poll doesn't represent or dictate anyone's rights, but rather allows others to make decisions based on where public opinion (both majority and minority opinion) sits. One problem with polls is that they do create a sense of ""certainty of opinion"" when this may not exist in reality as strongly... the way poll numbers are explained and reported often imply that the public have a well-defined and thought-out position on issues, which is not always the case of course. Importantly, social progress has been made even when it does not ""follow"" poll numbers (e.g. the legalization of same-sex marriage began long before a majority of Americans approved of it)... and the public followed (because it is now a majority opinion). I too sympathize with Rogers' concern, but I do not think that politicians simply do as polls dictate -- and we also see that polls (ie. public opinion) do follow legislation as well. e.g. capital punishment in Germany; attitudes towards banning smoking in bars/pubs (UK); and some aspects of the ACA. In other cases, legislation explicitly does not follow poll data (public opinion) e.g. in term of public support for gun control."	Wyoming	Vermont	Alaska	North Dakota	South Dakota	Ipsos does not use lists and so our ability to poll is mainly a function of population. The above are the smallest states by population.	Hurt	Primaries and caucuses are harder to poll because of the much smaller populations involved (primary voters in a specific state --> tiny population). So the polling is naturally less precise, and that means that the imprecise polling is part of the story, which usually makes the pollsters themselves look less able to make accurate predictions (because we are!). If we only had to poll general elections, we'd be seen as far more accurate :)	Not sure	They do not represent the individuals who will cast votes to determine primary election outcomes in each state. They paint a national rather than local picture. This doesn't mean they're irrelevant -- they do speak to national candidate popularity -- but they aren't going to be very useful to predict a specific state's outcome. It is apples and oranges. Whether you should ignore them depends on what you're interested in using the information for.	Not sure	I have no idea if it is fair. It is complicated, that is for sure.	Not sure	General election poll accuracy improves notably as we near Election Day. A year out, the average error is +/-9 points from the actual outcome in a 2-way race http://spotlight.ipsos-na.com/index.php/news/election-poll-accuracy-over-time/. They may be a general point of interest, again to indicate popularity, but they have very low predictive value. But early polls provide a general indicator of where public focus and opinion lies this far from Election Day: Trump and Sanders' poll numbers of late have changed and expanded the public discourse on issues like immigration and socialized medicine. So, whether you should pay attention to general election polls now depends on what you want to use them for.	Yes	More information is better than less; general election polls conducted now (just under a year out) speak to current candidate popularity and tracking movement on them over time can help us keep an eye on rising and falling stars.		"My response is ""Don't know."" Mode effects can impact in a lot of ways. We also know that presidential approval ratings are, on average, lower among online polls. There are simply differences by mode. The relative week-to-week change is more useful than the point estimate, anyway."	No	Every election people say that the future of polling hangs in the balance for some reason or another. Thus far that has not been the case.	Yes	"It could bias respondents in many ways, including towards (or against) Trump. Order effects are real and long-established. Best practice in polling (and the approach to which Ipsos adheres) is that you ALWAYS put the ""ballot"" question(s) as early in the survey as possible, ideally first (usually following any key demographics). There should be no issues-based questions that occur prior to ballot questions."	Neither	I don't think people are more or less likely to vote for Trump due to whether or not he has a pollster. I think it probably strengthens some of his core identity points about saying what he thinks and working outside the DC establishment... so it certainly doesn't hurt among those who support/like him anyway. But I doubt it impacts in any meaningful way with overall support among voters.	Yes	We currently poll the entire population, c. 11,000/month. So we are constantly polling American Muslims. They are simply identified in our nationally representative poll via a standard religion question. Of course, given their relatively low incidence (c. 1%), we can only speak about them meaningfully by aggregating multiple months together. We currently have no plans to do a targeted poll of American Muslims.	They are a useful means of identifying religious groups who often have clustering (though not identical) opinions on social, political, and economic issues. Ipsos also captures frequency of religious service attendance because this is a key measure of intensity/religiosity that is a critical dimension when making broader statements about religion in America.	Neither	They are the most well-known polling brand in the country. Their absence from horse-race polling will change the makeup of election polls this cycle, but there are plenty of newer pollsters to add to the roster.		"I don't think anyone is currently a household name the way Gallup is. I'm sure many of us endeavor to be, but I can't think of one that occupies that space. I don't like the question i'm afraid, because everyone must think that theirs ""should"" be equated with polling -- but I doubt any of us believe that there is a new brand name that *could* currently be equated with polling in the way Gallup's is, here in the US."	Yes	Of course: a prominent media partner is using them -- therefore they are good enough.	No	Prediction markets are simply aggregators of conventional wisdom, and conventional wisdom is no better a predictor of the election outcome now than a coin flip.	Not sure	"Aside from very clear-cut cases of fraud (which are extremely rare) or obvious push-polling, I'm not sure what a ""bad polling organization"" looks like. All the aggregators seem to factor predictive accuracy into their calculations, which is the best way to assess things in my mind."	No								
Daniel Gotoff	Lake Research Partners	About the same	I think we are not necessarily improving, but we are becoming more aware of flaws in our methodologies--over the course of a year, I think it's a wash.	Yes																																																							
Christopher Budzisz	Loras College																																																										
David Flaherty	Magellan Strategies	Worse	Landlines are declining, and additional cell phones are not going to address the sample coverage problems. Online panels are not even close to being representative of the 2016 likely or registered voting population at the state level. In addition, the number of panelists is so small a researcher can struggle to obtain more than 300 interviews.	No	We don't view response rates as as big of a problem for ballot test questions compared to the problems of sample having an acceptable coverage of the likely 2016 voting population.						Declined	I think the general public and media are more skeptical of public polling than they were before the 2012 election. I think that has harmed the political polling industry's image.		Iowa	Nevada				It should be stated that it is much more difficult to survey a Democrat primary than a Republican primary because of the age and racial demographics of the two populations. The average Democrat primary voter population contains a larger percentage of younger and minority voters, who are much more likely to be cell phone only or mostly than the Republican primary voter population. Forty percent of the GOP primary voting population is usually 65 or older, so you have a lot more landlines to work with. Picking states, though, Iowa is always very fluid up to the last minute, and voters say they will attend a caucus but then do not, because it can be very time consuming; it is not just, vote and go on home. Nevada is difficult to measure because of the multi-racial demographics, and younger voting population.	Not sure		Yes	The Republican primary voter populations of Iowa, Nevada, South Carolina and New Hampshire are not exactly the same when it comes to choosing a Presidential candidate. The most important issues and characteristics that these voters look for in a candidate often vary enough from the national GOP primary voting population.	Not sure		No	They are interesting to review, but historically they should not be reported on as a reliable forecast.	Yes	I would say yes. When you are trying to measure and understand how the non-primary voting population and likely independent voters are viewing the candidates during a primary can generate insights and information that is valuable to the eventual nominee. Simply put, a candidate's ability to be trusted and accepted by the all-important middle general election voter can be seriously damaged during the primary season. Knowing if that is happening is important to know.	Neither	"In our view the sample is more important than the interview method for getting the ballot test right. If the sample in any survey is ""limited"" or lacking in coverage of the true GOP primary voting population, then the survey will likely be less accurate. If Trump does turn out a significant number of voters that have not participated in a GOP primary before, and the sample is not drawn across those voters, the survey's accuracy will suffer. Although we find that IVR surveys pick up more older, Tea-Party affiliated voters than live surveys, it still comes down to the sample used and how it was selected from a list or voter file."	No		Yes	"We don't believe any specific, issue based questions should be asked before the ballot test. We believe questions about immigration before a ballot test could perhaps influence the ballot test. However, asking a ""most important issue"" question from a list of 5 or more issues is fine, or an open-ended verbatim."	Hurts	Survey research is one of the most reliable methods for a campaign to generate actionable information and make decisions. Not having a pollster limits anyone's ability to measure and understand the voting population.	No		Depending on the state or district you are surveying, it can be helpful to know religious affiliation.					Not sure	It all depends on how representative the sample or panel is that will be used in their survey.	Not sure	Again, if the participants are representative of the voting population, they can be accurate. If they aren't, they will not be accurate.	Not sure	They all have their standards, which is better than no standards, I guess.									
Barbara Carvalho	Marist College	About the same	About the same. Still lots of experimentation, different methods...good and bad. Individual organizations should be assessed not use one broad stroke to describe all polling.	No	1 - Response rates are measuring more than whether or not people cooperate. With the proliferation of telephone numbers and an inability to identify HH/personal numbers from non-eligible/unassigned/non-working/blocked numbers the response rate calculators of an earlier era emphasize the worst case characterization; 2 - telephone surveys that include a larger proportion of cell phone interviews than landline are quite representative and require little sample balancing. The issue isn't the ability of scientific telephone surveys to be representative but rather the cost to accomplish it.	About the same		11	11	AAPOR response rate calculator	Declined	Polls are wrong is a more interesting story than when the polls do well. Lumping all methods together distorts the accuracy of polling. In addition, requiring exactitude beyond the methodology is a prescription for failure. There is a need for clarification about the uses and limits of polling.	Article would have been better if more people who understand polling had been interviewed.						Caucus states, low turnout	Helped	They have told the narrative and reined in conventional wisdom that Trump would be a summer romance.	No	Public polls still provide a national narrative but need to be understood for what they are and are not. They draw a picture of candidates' name recognition, regional and demographic support, and identify issues of concern among strong party activists and independent voters. After all, the debates have demonstrated this has been an unusually national election. They are not, however, predictive of state contests.	No	This gets back to the problem with assuming polls have a precision they do not. This was particularly the case for the early debates when polls were used to distinguish between relatively unknown candidates propping up some and ignoring others. Conduct two debates, randomly assigning participants to each one.	Yes	The polls a year out are not predictive but provide a narrative for understanding the campaign. They provide insight into candidates' strategy, strengths, and weaknesses. The candidates use them. The public and media should have access to the same information.			Live-interviewer polls	The FCC's Telephone Consumer Protection Act doesn't allow automated calls to cell numbers, only landlines. More than 6 in ten Americans are cell phone only or cell phone mostly. IVR polls cannot call cell phones and have a huge coverage problem. But, there's also a lot more that goes into polling than live interviewers.	No	If or when Trump becomes less popular, he will decline in the polls, as well.	Yes	It's best to ask candidate preference questions prior to asking any other issues.	Neither	Trump loves the polls.	No		It's important when measuring religion to include a distinction between those who practice their faith and those who identify with the religion but do not practice.	Neither	It's a business decision by Gallup. There are lots of other horse-race polls.	No	Gallup is still doing a lot of public polling.	Not sure	I have no idea. Once they start regularly releasing public polls that have accountability they will be evaluated. It appears to be a serious effort.	No	Prediction markets change all the time, too.		Depends. It's like saying polls are good or polls are bad. Some are doing a good job and others are not.		I think 1 - it's confusing to aggregate polls with completely different methods; 2 - aggregators need to make sure polling firms included exist and are transparent about their methods.							
Steve Koczela	MassINC Polling Group													New Hampshire	Iowa				Small populations, really high importance, independents in New Hampshire, caucus participation in Iowa.	Not sure	Hard to say. I don't know how the public is reacting.	No	That shifty Nate Silver dude, I dunno about him. Seriously, I think there is value other than understanding how the delegate math will play out. Lots of people just want to know who the country is reacting to and listening to, not who is going to win every state.	No	I prefer the new CNN method of adding in Iowa and New Hampshire polls. If you are going to use polls at all, it seems like including the early states makes sense.	Yes	There is a difference between interesting and predictive. It's interesting to know how the nation perceives the various players, even if it doesn't tell us how the national ballot or the Electoral College will play out next year.											No		Very meaningful. There is always more granularity. But as pollsters, we have to look for categories large enough that they can be observed with reasonable sample sizes.					Yes	Everyone is working hard to figure out the online polling. Good for all of them for going out on a limb.	Not sure	I don't follow it closely enough to know for sure.	Very badly	I guess I am not sure how things have changed. But it seems like terrible polls are still in there.									What method do you use for political polling? What method do you think is best? What other methods would you consider? Do you think polls have contributed to Trump's rise?
Mark Mellman	Mellman Group																																																										
Patrick Murray	Monmouth University																																																										
Kyle Dropp	Morning Consult	Better	The polling industry is in flux and is undergoing dramatic changes. With any industry that is going through changes, there are bound to be some errors, but we believe overall that the polling industry is moving in the right direction. We now have more information at our fingertips and an incredibly diverse set of data collection methods that are allowing us to analyze and research public opinion data like never before. Moreover, validation methods, such as linking individuals to voter files, comparing public opinion data to election results and comparing likely voter models to actual election outcomes, are improving as we experiment with these new methods. On top of it all, the new technology behind polling is allowing us to aggregate all of the data so that people can access it easily. 	Yes	Most polls are highly accurate and do a great job of capturing the mood of the electorate at any given time. With that in mind, we and others believe the future of polling is online. The best phone surveys have very low response rates and such rates may continue to decline as Americans eschew landlines and move to cell phones or spend more time online.	Easier	Without doubt, it has become easier to obtain responses from voters since 2014. More and more people are accessible online, online vendors are adding millions of adults annually, and we are finding new and better ways to reach more diverse demographic groups. As the Pew Research Center has shown, about nine in 10 Americans are now online, compared with about half in 2000. Even six in 10 seniors now go online -- a fivefold increase from 2000.				Neither	As we said before, we think the polling industry is in flux. There is more scrutiny than ever directed toward polling results and that is a good thing. We have also seen more data scientists, statisticians and computer scientists driven to the field, which leads to more innovation. For example, at Morning Consult, we have been able to recruit data scientists from diverse backgrounds and industries such as Google, the NBA, etc. We believe that diversity will be key in helping polling go through its current evolution. 								Not sure	There should be much more focus on policy analysis and diving into the crosstabs instead of looking at the overall topline or horse race results. We recognize that this might sound odd coming from a firm that releases weekly tracking polls that examine primary and general election results. However, our focus has been on building large, national datasets with hundreds of thousands of interviews that let us dive into demographics and crosstabs on key policy issues such as healthcare, energy, technology and finance as the country looks to elect its next leader. This is one reason why we launched Morning Consult Intelligence -- to make it easier to find survey questions based on policy or issue topics, in addition to primary polling.					Yes	Yes, voters and the media should be paying attention to general election polls. These polls can vary a lot when they are conducted far in advance of an election. Professors Andrew Gelman and Gary King, for example, have helped explain the puzzle of why pre-election polls vary so much when election outcomes are relatively predictable, but general election polls can provide a general general snapshot of the electoral landscape.			Neither	I said neither because it’s a stretch in my view to place IVR and online polls in the same category. IVR polls tend to have key methodological drawbacks such as they must be shorter in length, there are huge levels of dropout, there are limitations in answer choice randomization, and there are limitations in voter validation. Online and live-interviewer phone polls have limitations too, but they afford researchers the opportunity to test a wider range of hypotheses. We have a large experiment currently in the field testing this idea right now. Basically, we want to understand why Trump is doing better online than in live-interviewer phone polling and we test a number of prevailing explanations. Namely, we examine whether respondents are less likely to say they support Trump when they are talking to a live interviewer than when they are answering a survey anonymously online, a social desirability hypothesis, or whether online and live telephone samples are different and therefore explain this inconsistency. In our experiment, more than 3,000 registered Republicans are randomly assigned to complete a series of election questions online, by IVR or by live telephone.	No	Polling is much bigger than the 2016 presidential election. The future of polling is dependent on improvements in sampling and validation.	Yes	Yes, question ordering is very important and there are a number of studies that point to this. Survey practitioners must be very careful to avoid priming effects that are caused by placing sensitive topics in front of other questions.																								
Chris Borick	Muhlenberg College	Not sure	I'm really not sure where we are as an industry. The recent failures abroad and in Kentucky certainly have created concern that our current methods might not be adequately designed for 2016.	Yes	In general I continue to be surprised that the dramatic decline in response rates in telephone polls has not been more detrimental to accuracy that what we have seen, Some of the recent failures may be a harbinger that the response rate threat is finally materializing, however I think the relatively older electorate and marginally higher response rates in that group may continue to buffer more dramatic declines in accuracy.	Harder		10	12	AAPOR RR3	Declined	I think the international and domestic accuracy struggles have undermined public confidence on the polls. 2014 wasn't a particularly robust cycle either so I think that skepticism is probably pretty significant as we head into 2016.	There is of course plenty to be concerned about if majority public opinion always ruled the day but in reality opinion remains one of many factors that drive policy decisions.	Iowa					I think the caucus system poses some particularly challenging issues for pollsters.	Hurt	In general I think the variability in turnout and election rules across states and elections for primaries makes it a harder environment for polling and thus the performance of polls in these races could undermine public confidence. I also believe the presence of national level primary polling and state specific polls may lead to public confusion about the polls and add to the erosion of confidence in their predictive ability.	Yes	In general, yes. They measure an imaginary race and thus don't tell us much.	Not sure	I'm torn about this one. I don't think national polls are a great way of choosing who gets to be on that stage, but I'm not very confident in any of the alternative selection methods. Someone is always going to be angry about not getting the opportunity to debate or the number of people on the stage so I'm not going to lay the current dissatisfaction squarely on the use of national polling.	No	They shouldn't be given much attention at all. The primary season will define the eventual party nominees to a large degree and thus by the time the field is set the race is likely to be quite different that what polls may be showing now.	Yes	I guess they make for good discussion and perhaps that's a value.	Live-interviewer polls	While there may be some Trump-specific dynamic at play that advantages IVR and Internet polls, I'm going to stick with live-interviewer polls because of their more complete sampling frames. As with lots of things Trump, his polling may defy conventional wisdom. We shall see.	Not sure	It go too far to say the future of polling depends on Donald Trump's fate but certainly if the polls fail on Trump the damage will be really significant given the spotlight on him. I assume Trump would be happy to think that the future of polling and everything depends on him.	Not sure	Order effects are tricky here. In general it seems that you would want to measure candidate preference before you build a mental set of issues with respondents. However having Trump related questions before asking about immigration may have some impact on preferences towards that issue given the deep connection he has with that issue. Sounds like a great situation to try a split-sample experiment.	Helps	It probably is a modest help to his narrative that he is independent of everyone and everything.	No	I would love to see much more rigorous work on Muslim American opinion but we don't have the resources to undertake that kind of effort right now.	They are most valuable when you interact them with other questions such as attendance at services.	Neither		No	Not on Gallup's past level but if there was one I would say it's Pew.	Yes	There are plenty of questions surrounding the Survey Monkey approach, but given their wide reach and fairly high degrees of transparency, I think they are worthy of a partnership with a major media outlet. I feel the same about YouGov and the New York Times.	Not sure	I think markets are a useful way of analyzing elections but as a complement rather than a substitute to polling.	OK	I think there is an effort but it's incomplete.	Yes	There are but I'm not going to call them out here.	Hillary Clinton		Other (please specify)	Not sure	49	221	
John Broder	New York Times																																																										
Matthew Towery	Opinion Savvy	About the same	It's hard to determine whether the industry has changed dramatically in the past year, given that there have been few salient elections in the US. That said, state and local polls showed mixed results, and polls of the Canadian election were generally accurate.	Not sure	While most polls that use the telephone exclusively may be suspect in general elections, the same is not true of smaller elections with low voter turnout. Similarly, I would not trust a poll without a telephone instrument for nearly any election, given the current demographic makeup of the electorate. If we seek to capture all voting demographics, then blended, mixed-mode samples are currently the best solution.						Declined	Obviously, there were several high profile calamities in the past three years. The best I can say is this: the field is evolving, and some pollsters are succumbing to natural selection.	"I disagree that polls are a ""majoritarian monstrosity;"" however, I believe that the ways in which public opinion polls are publicized and used as forecasts of distant-future events are incorrect. Lepore also quoted Sidney Verba (with whom any political scientist worth his or her weight in pennies should be familiar), who recognizes the democratic importance of surveys in the context of public issues. That is, ""horse race"" polls might produce a snapshot of the likely electorate at a given time, but more importantly, issues polling provides evidence of representational accountability. If the public feels strongly about one policy or another, then it is the responsibility of elected officials to consider these positions in their policy decisions. Similarly, candidates should use ""horse race"" polls to understand their key voter demographics, and the media should accompany these polls with an analysis that excludes forecasts of events beyond --roughly-- one month."									No	"Again, I believe that these polls are valuable as a snapshot of the electorate; however, we must not overstate their value. Early primary polls are not forecasts -- they are not the result of a predictive model, and they are only useful in understanding the voting population. Take these polls for what they are worth, e.g. ""If the primary were held tomorrow, likely voters would prefer Trump over other candidates by a margin of X%, given a Y% margin of error."""	Yes	"Normally, this would perhaps be unfair. But when there are more than 10 candidates, the herd must be culled. Without an alternative presented (other than ""include everyone,"" which would be a nightmare), polls are the best option. I've seen proposals to select candidates for the ""main stage"" randomly, but I don't think that this would be productive in narrowing the field."	Yes	Again, I will present the caveat that the media and its audience should not overstate the results. Hypothetical candidate match-ups can range from utterly useless, to somewhat helpful for an undecided voter who wishes to select a viable candidate in the primary.			IVR and online polls	This again comes with a caveat: IVR and online are closer to correct, given a population of those who have formed an opinion, at a precise point in time. I buy into Pew's modal bias theory, that respondents are less likely to state their true intentions, given a live interviewer. Add to this the non-probability nature of online polling, which tends to favor those who have already formed an opinion, and you will likely have a better estimate of decided voters' current opinions.	Not sure		Yes	"I think that's rather obvious, no? Pollsters constantly conduct this type of malpractice, and it's downright insulting to the industry. Here's a tip: if your horse race questions are so valuable to you as a ""public media"" pollster, then put them at the beginning of the survey. Any previous information -- however innocuous -- can potentially influence the choice of the respondent. Given the volatile nature of the immigration debate, this should have been a no-brainer (in the absence of an agenda)."	Neither	"I think that we, as pollsters, tend to overestimate our own salience. While I'm sure that Trump's abstention from hiring a pollster doesn't hurt his ""outsider"" image, it probably didn't help to any significant degree."				Neither		No		Not sure	I am unaware of SurveyMonkey's current methodology, but I would assume that it is similar to that of YouGov. In the past, SurveyMonkey produced studies following prominent elections, which showed promising results.	Not sure	I have only read articles that mention this theory anecdotally, but it certainly seems possible.	OK	I've seen some polls included that are laughably bad, while others with solid methodology are sometimes neglected. It's a mixed bag, and it is very much dependent on the site and its relationship with certain pollsters.	Yes	Public Religion Research Institute - presented a national poll with an N of 147 likely voters (horse race) IBD/TIPP - N of just over 300 in multiple national polls; inconsistent results; does not publish methods, cross tabs, etc. Fairleigh Dickinson - roughly the same as IBD/TIPP.							In the past year, much attention has been placed on millennial voters and the apparent difficulty in understanding their opinions. What do you believe pollsters can or should do to measure the opinions of this generation accurately?
Beth Chunn	Rasmussen Reports	About the same	Although it is harder and harder to get people to answer phone polls, polling companies have done a better job in 2015 trying to balance out responses with new methods of reaching individuals who may have abandoned landlines.	No	All of us are feeling our way through new polling methods, but at the same time we are focusing more precisely than ever on defining our demographic categories and mapping their historical voting patterns. At the same time, we are analyzing how we have applied our weightings in the past to ensure that we get the most representative samples in the future.																																																						
J. Ann Selzer	Selzer & Company										Neither		Polls are not meant to be a blueprint for policy. But, it is helpful to know where a majority stand--imagine a world where you did not know that.	Nevada					Relatively new as an early state. It's a caucus state, so low incidence.	Not sure	I'm too close to know.	Yes	There is no national primary. So, a sample of likely primary/caucus voters on a national level is not a meaningful universe. Fox News made this somewhat meaningful by deciding who would debate on the mainstage using this respondent base.	No	Candidates' first chances to win happen in Iowa, New Hampshire, South Carolina and Nevada. So candidates spend more time and money there, with the consequence that likely voters/caucusgoers know them better. To me, this would be the major consideration--how candidates are faring in polls in these states--that's IF you want to use polls at all. I would think other hard indicators of candidates' seriousness--number of campaign offices/staff, amount of money raised, number of visits to early states--could be factored in. Over a hundred candidates have filed to run officially, so you have to have some standards for the debates. Could you factor in some sort of national pulse? OK. Not sure how you mix this all together, but these are the ingredients I'd want in the mix.	Yes	"Inherent in questions about ""paying attention"" seems to be a concern that polls this far out do not predict the actual outcome. To me, it's silly to think they would. So, the measurement is valid for the mood of the electorate at that point in time. And, it's useful to know. But, if we thought polls months ahead of any primary, caucus, or general election event were predictive, we'd just stop polling."			Live-interviewer polls		No		Not sure	It depends on how the questions are phrased, of course.	Neither																							
Don Levy	Siena College																																																										
Jay H. Leve	SurveyUSA																					Yes	"When I was 7, I received a book of Bennett Cerf cartoons. One cartoon showed a man bent over, under a street lamp, apparently looking for something. A passerby approached and asked, ""Mister, what are you looking for?"" The man said, ""A quarter."" The passerby asked, ""Is this where you dropped it?"" The man said, ""No, i dropped it over there, but the light is better here."" ... Fast forward 50 years and we find America's most distinguished pollsters looking for primary voters NOT where they are (In Iowa, New Hampshire, South Carolina and Nevada), but in 46 other states ... all because ""the light is better there."" National primary polls are worse than meaningless. We've never taken one in 25 years."	No		Yes				IVR and online polls	A CBS NY Times poll released today finds that Americans disagree with Trump on his plan to keep Muslims from entering the USA. An identical poll, conducted using recorded-voice, likely would have found the opposite. (See pre-election polling from 1994 on California's Proposition 187 to understand why.)	No		Yes		Neither		Not sure		Religion is a useful crosstab, provided you have enough respondents in the sample from which to draw conclusions. If your survey has 8 Jewish and 6 Muslim respondents, don't bother. But in a survey about (say) Pope Francis, differentiating between Catholics and non-Catholics is appropriate and useful.	Neither	See Gallup's general election performance in 2004, when it called the wrong winner in 42% of cases (5 wrong winners out of 12 STATES polled). That's almost impossible to do. ... And it was the last time Gallup tried to poll STATES. Those focused on what Gallup has said in recent months are missing the much larger trend line, which goes back more than a decade.	No		Not sure		Not sure		Not sure		Yes								
Gabriel Joseph	The FreeEats Network	Worse	No access to the voters. Surveys need to be 100% mobile.	Yes	Same as above	Easier	We have created an opt-In network of mobile users who we pay for the delivery of the messages we send.	50	10	Conversions. How many people we contact versus how many provide answers to questions we ask.	Declined	Pollsters are wrong. We all want to be with a winner.	None							Hurt	They are wrong. Being wrong hurts your reputation.	Yes	It is a popularity contest at this point.	No	They are easy to manipulate.	No	See answers above.	Yes	People believe in them. They shape expectations. All pollsters have a 50% chance of being right. Sometimes they are.	IVR and online polls	History	No	There are no undecided voters in the polling booth.	Yes		Helps																							
Andrew Smith	University of New Hampshire	About the same		No		About the same		25	25	AAPOR #4	Declined	The inclusion of polls with methodologies that do not represent best practices as well as partisan polls into poll aggregation sites has tarnished the reputation of polls that adhere to higher standards.		Iowa					Very low turnout	Not sure	"Media are responsible for the focus on polls and misuse of polling information. The GOP use of national ""primary electorate"" polls is especially egregious."	Yes	National polls are meaningless. Presidential nominations are a sequential process.	No	One of the stupidest ideas the media has come up with! Have two debates and randomly assign candidates to one or the other.	No	Little attention should be paid until voters start paying attention, which will be after Labor Day.	No	See above	Live-interviewer polls	Only the most committed, angry voter would talk to a computer.	No	This is a really stupid question!	Yes	There is a whole body of literature about question order and context effects.	Neither		No		Church/service attendance is a much better predictor of political behavior than denomination.	Neither		No		No	Where is the random sample?	No	Those markets depend almost solely on polls!	Badly		Yes	Any organization that does work for candidates or parties. And IVR polls.							
