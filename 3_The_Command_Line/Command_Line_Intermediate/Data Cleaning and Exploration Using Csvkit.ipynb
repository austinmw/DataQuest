{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Csvkit\n",
    "\n",
    "So far, we've been using the default command line tools to clean, munge, and explore data. Tools like wc and head are useful tools, but weren't designed specifically for working with datasets and are limited in many ways. These tools lack features specific to working with tabular datasets, like parsing the header row or understanding the row and column layout. Because of this, in the Data Munging Using the Command Line challenge, you had to specifically compute the number of lines in each CSV file using the wc tool and use that number to select just the non-header rows using the tail tool. You then had to repeat this for each CSV file you were trying to merge into the resulting, single file!\n",
    "\n",
    "In this mission, we'll learn about the Csvkit library, which supercharges your workflow by adding 13 new command line tools specifically for working with CSV files. We'll focus on these 5 tools from Csvkit:\n",
    "\n",
    "- csvstack: for stacking rows from multiple CSV files.\n",
    "- csvlook: renders CSV in pretty table format.\n",
    "- csvcut: for selecting specific columns from a CSV file.\n",
    "- csvstat: for calculating descriptive statistics for some or all columns.\n",
    "- csvgrep: for filtering tabular data using specific criteria.\n",
    "\n",
    "We'll be using csvkit version 0.9.1 in this mission and you can read about the installation procedure in the documentation. We'll continue to work with the same 3 datasets on housing affordability:\n",
    "\n",
    "- Hud_2005.csv,\n",
    "- Hud_2007.csv,\n",
    "- Hud_2013.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hud_2005.csv\n",
      "Hud_2007.csv\n",
      "Hud_2013.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd data/\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2: Csvstack\n",
    "\n",
    "To start, let's circle back to the task of merging 3 CSV files into 1 file. We can use csvstack tool to consolidate the rows from multiple CSV files and redirect the stdout to a new file:\n",
    "\n",
    "    csvstack file1.csv file2.csv file3.csv > final.csv\n",
    "\n",
    "As long as the header row for each file in the stdin to csvstack is the same, the first row in the resulting file will match this header row. After the header row, final.csv will contain all of the non-header rows from file1.csv, then all of the non-header rows from file2.csv, then finally the non-header rows from file3.csv. If you don't redirect the stdout of csvstack to a file or a tool like head, the full output will be rendered in the terminal. This can cause your terminal to grind to a halt as it tries to process and display all of the output and you want to be extra careful to avoid doing so.\n",
    "\n",
    "If you peeked at the documentation, you may have noticed that the behavior of csvstack can be modified using a few different flags. For example,\n",
    "\n",
    "if you want to be able to trace the file where each row originated from in the merged file, you can use the -g flag to specify a grouping value for each filename. When stacking the rows from a file, csvstack will add the corresponding value in a new column. Lastly, you can use the -n flag to specify the name of this new column. The following code will create a new column named origin, containing the values 1, 2, or 3 depending on which file that row originated from:\n",
    "\n",
    "    csvstack -n origin -g 1,2,3 file1.csv file2.csv file3.csv > final.csv\n",
    "\n",
    "The rows in final.csv that originated from file1.csv will contain the value 1 in the origin column and those from file2.csv will contain the value 2 in the origin column. Let's now use csvstack to combine the 3 datasets on U.S. housing affordability from the last challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#head -1 data/*.csv\n",
    "cd data/\n",
    "\n",
    "csvstack -n year -g 2005,2007,2013 Hud_2005.csv Hud_2007.csv Hud_2013.csv > Combined_hud.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined_hud.csv\n",
      "Hud_2005.csv\n",
      "Hud_2007.csv\n",
      "Hud_2013.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd data/\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year,CONTROL,AGE1,BEDRMS,PER,REGION,LMED,FMR,L30,L50,L80,IPOV,BUILT,STATUS,VACANCY,TENURE,NUNITS,TYPE,VALUE,ZINC2,ROOMS,ZADEQ,ZSMHC,WEIGHT,METRO3,STRUCTURETYPE,OWNRENT,UTILITY,OTHERCOST,COST06,COST12,COST08,COSTMED,TOTSAL,ASSISTED,GLMED,GL30,GL50,GL80,APLMED,ABL30,ABL50,ABL80,ABLMED,BURDEN,INCRELAMIPCT,INCRELAMICAT,INCRELPOVPCT,INCRELPOVCAT,INCRELFMRPCT,INCRELFMRCAT,COST06RELAMIPCT,COST06RELAMICAT,COST06RELPOVPCT,COST06RELPOVCAT,COST06RELFMRPCT,COST06RELFMRCAT,COST08RELAMIPCT,COST08RELAMICAT,COST08RELPOVPCT,COST08RELPOVCAT,COST08RELFMRPCT,COST08RELFMRCAT,COST12RELAMIPCT,COST12RELAMICAT,COST12RELPOVPCT,COST12RELPOVCAT,COST12RELFMRPCT,COST12RELFMRCAT,COSTMedRELAMIPCT,COSTMedRELAMICAT,COSTMedRELPOVPCT,COSTMedRELPOVCAT,COSTMedRELFMRPCT,COSTMedRELFMRCAT,FMTZADEQ,FMTMETRO3,FMTBUILT,FMTSTRUCTURETYPE,FMTBEDRMS,FMTOWNRENT,FMTCOST06RELPOVCAT,FMTCOST08RELPOVCAT,FMTCOST12RELPOVCAT,FMTCOSTMEDRELPOVCAT,FMTINCRELPOVCAT,FMTCOST06RELFMRCAT,FMTCOST08RELFMRCAT,FMTCOST12RELFMRCAT,FMTCOSTMEDRELFMRCAT,FMTINCRELFMRCAT,FMTCOST06RELAMICAT,FMTCOST08RELAMICAT,FMTCOST12RELAMICAT,FMTCOSTMEDRELAMICAT,FMTINCRELAMICAT,FMTASSISTED,FMTBURDEN,FMTREGION,FMTSTATUS\n",
      "\n",
      "  154118 Combined_hud.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd data/\n",
    "head -1 Combined_hud.csv\n",
    "echo\n",
    "wc -l Combined_hud.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Csvlook\n",
    "\n",
    "While head allows you to quickly observe the first few rows in a file, it doesn't attempt to format the rendered output at all. CSV files are tabular and it's incredibly useful to observe this structure and other data tools like Pandas and Microsoft Excel factored that notion in when displaying tabular data. Thankfully, we can use the csvlook tool to display tabular data in the table format we're used to.\n",
    "\n",
    "The csvlook tool parses CSV formatted data from it's stdin and outputs a pretty formatted table representation of that data to it's stdout:\n",
    "\n",
    "    head -10 final.csv | csvlook\n",
    "\n",
    "Let's use csvlook to explore the first few rows from the CSV file we created in the last screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  year |         CONTROL | AGE1 | BEDRMS |  PER | REGION |   LMED | FMR |    L30 |    L50 |    L80 |  IPOV | BUILT | STATUS | VACANCY | TENURE | NUNITS | TYPE |  VALUE |  ZINC2 | ROOMS | ZADEQ | ZSMHC |     WEIGHT | METRO3 | STRUCTURETYPE | OWNRENT |  UTILITY | OTHERCOST |   COST06 |     COST12 |   COST08 |  COSTMED | TOTSAL | ASSISTED |  GLMED |   GL30 |   GL50 |   GL80 |   APLMED |       ABL30 |       ABL50 |  ABL80 |    ABLMED | BURDEN | INCRELAMIPCT | INCRELAMICAT | INCRELPOVPCT | INCRELPOVCAT | INCRELFMRPCT | INCRELFMRCAT | COST06RELAMIPCT | COST06RELAMICAT | COST06RELPOVPCT | COST06RELPOVCAT | COST06RELFMRPCT | COST06RELFMRCAT | COST08RELAMIPCT | COST08RELAMICAT | COST08RELPOVPCT | COST08RELPOVCAT | COST08RELFMRPCT | COST08RELFMRCAT | COST12RELAMIPCT | COST12RELAMICAT | COST12RELPOVPCT | COST12RELPOVCAT | COST12RELFMRPCT | COST12RELFMRCAT | COSTMedRELAMIPCT | COSTMedRELAMICAT | COSTMedRELPOVPCT | COSTMedRELPOVCAT | COSTMedRELFMRPCT | COSTMedRELFMRCAT | FMTZADEQ   | FMTMETRO3 | FMTBUILT  | FMTSTRUCTURETYPE | FMTBEDRMS | FMTOWNRENT | FMTCOST06RELPOVCAT | FMTCOST08RELPOVCAT | FMTCOST12RELPOVCAT | FMTCOSTMEDRELPOVCAT | FMTINCRELPOVCAT | FMTCOST06RELFMRCAT | FMTCOST08RELFMRCAT | FMTCOST12RELFMRCAT | FMTCOSTMEDRELFMRCAT |     FMTINCRELFMRCAT | FMTCOST06RELAMICAT | FMTCOST08RELAMICAT | FMTCOST12RELAMICAT | FMTCOSTMEDRELAMICAT | FMTINCRELAMICAT | FMTASSISTED | FMTBURDEN          | FMTREGION | FMTSTATUS |\n",
      "| ----- | --------------- | ---- | ------ | ---- | ------ | ------ | --- | ------ | ------ | ------ | ----- | ----- | ------ | ------- | ------ | ------ | ---- | ------ | ------ | ----- | ----- | ----- | ---------- | ------ | ------------- | ------- | -------- | --------- | -------- | ---------- | -------- | -------- | ------ | -------- | ------ | ------ | ------ | ------ | -------- | ----------- | ----------- | ------ | --------- | ------ | ------------ | ------------ | ------------ | ------------ | ------------ | ------------ | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | ---------------- | ---------------- | ---------------- | ---------------- | ---------------- | ---------------- | ---------- | --------- | --------- | ---------------- | --------- | ---------- | ------------------ | ------------------ | ------------------ | ------------------- | --------------- | ------------------ | ------------------ | ------------------ | ------------------- | ------------------- | ------------------ | ------------------ | ------------------ | ------------------- | --------------- | ----------- | ------------------ | --------- | --------- |\n",
      "| 2,005 | 100,006,110,249 |   43 |      3 | True |      3 | 47,954 | 680 | 10,359 | 17,263 | 27,615 | 9,930 | 1,980 |   True |      -6 |   True |   True | True | 90,000 | 20,000 |     8 |  True |   855 | 2,916.527… |      5 |          True |    True | 160.167… |   33.333… | 791.636… | 1,139.176… | 900.349… | 791.636… | 20,000 |       -9 | 47,954 | 10,359 | 17,263 | 27,615 | 33,567.8 | 15,390.514… | 25,647.886… | 41,028 | 49,872.16 |  0.513 |      59.581… |            3 |     201.410… |            4 |      73.529… |            2 |         63.493… |               4 |        318.887… |               4 |        116.417… |               3 |         72.213… |               4 |        362.678… |               4 |        132.404… |               3 |         91.368… |               5 |        458.883… |               4 |        167.526… |               3 |          63.493… |                4 |         318.887… |                4 |         116.417… |                3 | 1 Adequate |        -5 | 1980-1989 | 1 Single Family  | 3 3BR     | 1 Owner    | 4 200%+ Poverty    | 4 200%+ Poverty    | 4 200%+ Poverty    | 4 200%+ Poverty     | 4 200%+ Poverty | 3 GT FMR           | 3 GT FMR           | 3 GT FMR           | 3 GT FMR            | 1951-01-14 01:00:00 | 4 60 - 80% AMI     | 4 60 - 80% AMI     | 5 80 - 100% AMI    | 4 60 - 80% AMI      | 3 50 - 60% AMI  |             | 3 Greater than 50% |        -5 |        -5 |\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "head -2 Combined_hud.csv | csvlook # too many cols to display table properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Csvcut\n",
    "\n",
    "Csvlook returned a table formatted output of the merged CSV file. Let's now explore individual columns using the csvcut tool. Using the csvcut command with just the -n flag parses and displays all the columns in a CSV file along with an unique integer identifier for each column:\n",
    "\n",
    "    csvcut -n Combined_hud.csv\n",
    "\n",
    "will output:\n",
    "\n",
    "    1: year\n",
    "    2: AGE1\n",
    "    3: BURDEN\n",
    "    4: FMR\n",
    "    5: FMTBEDRMS\n",
    "    6: FMTBUILT\n",
    "    7: TOTSAL\n",
    "\n",
    "ou can use the integer identifier for each column and the -cc flag to select just a specific column:\n",
    "\n",
    "    csvcut -c 1 Combined_hud.csv\n",
    "\n",
    "will output just the year column. You want to avoid displaying the entire column since it contains 154118 rows and your terminal window will severely come to a halt attempting to display all that information. Instead, you can pipe the column output to head to preview just the first n rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: year\n",
      "  2: CONTROL\n",
      "  3: AGE1\n",
      "  4: BEDRMS\n",
      "  5: PER\n",
      "  6: REGION\n",
      "  7: LMED\n",
      "  8: FMR\n",
      "  9: L30\n",
      " 10: L50\n",
      " 11: L80\n",
      " 12: IPOV\n",
      " 13: BUILT\n",
      " 14: STATUS\n",
      " 15: VACANCY\n",
      " 16: TENURE\n",
      " 17: NUNITS\n",
      " 18: TYPE\n",
      " 19: VALUE\n",
      " 20: ZINC2\n",
      " 21: ROOMS\n",
      " 22: ZADEQ\n",
      " 23: ZSMHC\n",
      " 24: WEIGHT\n",
      " 25: METRO3\n",
      " 26: STRUCTURETYPE\n",
      " 27: OWNRENT\n",
      " 28: UTILITY\n",
      " 29: OTHERCOST\n",
      " 30: COST06\n",
      " 31: COST12\n",
      " 32: COST08\n",
      " 33: COSTMED\n",
      " 34: TOTSAL\n",
      " 35: ASSISTED\n",
      " 36: GLMED\n",
      " 37: GL30\n",
      " 38: GL50\n",
      " 39: GL80\n",
      " 40: APLMED\n",
      " 41: ABL30\n",
      " 42: ABL50\n",
      " 43: ABL80\n",
      " 44: ABLMED\n",
      " 45: BURDEN\n",
      " 46: INCRELAMIPCT\n",
      " 47: INCRELAMICAT\n",
      " 48: INCRELPOVPCT\n",
      " 49: INCRELPOVCAT\n",
      " 50: INCRELFMRPCT\n",
      " 51: INCRELFMRCAT\n",
      " 52: COST06RELAMIPCT\n",
      " 53: COST06RELAMICAT\n",
      " 54: COST06RELPOVPCT\n",
      " 55: COST06RELPOVCAT\n",
      " 56: COST06RELFMRPCT\n",
      " 57: COST06RELFMRCAT\n",
      " 58: COST08RELAMIPCT\n",
      " 59: COST08RELAMICAT\n",
      " 60: COST08RELPOVPCT\n",
      " 61: COST08RELPOVCAT\n",
      " 62: COST08RELFMRPCT\n",
      " 63: COST08RELFMRCAT\n",
      " 64: COST12RELAMIPCT\n",
      " 65: COST12RELAMICAT\n",
      " 66: COST12RELPOVPCT\n",
      " 67: COST12RELPOVCAT\n",
      " 68: COST12RELFMRPCT\n",
      " 69: COST12RELFMRCAT\n",
      " 70: COSTMedRELAMIPCT\n",
      " 71: COSTMedRELAMICAT\n",
      " 72: COSTMedRELPOVPCT\n",
      " 73: COSTMedRELPOVCAT\n",
      " 74: COSTMedRELFMRPCT\n",
      " 75: COSTMedRELFMRCAT\n",
      " 76: FMTZADEQ\n",
      " 77: FMTMETRO3\n",
      " 78: FMTBUILT\n",
      " 79: FMTSTRUCTURETYPE\n",
      " 80: FMTBEDRMS\n",
      " 81: FMTOWNRENT\n",
      " 82: FMTCOST06RELPOVCAT\n",
      " 83: FMTCOST08RELPOVCAT\n",
      " 84: FMTCOST12RELPOVCAT\n",
      " 85: FMTCOSTMEDRELPOVCAT\n",
      " 86: FMTINCRELPOVCAT\n",
      " 87: FMTCOST06RELFMRCAT\n",
      " 88: FMTCOST08RELFMRCAT\n",
      " 89: FMTCOST12RELFMRCAT\n",
      " 90: FMTCOSTMEDRELFMRCAT\n",
      " 91: FMTINCRELFMRCAT\n",
      " 92: FMTCOST06RELAMICAT\n",
      " 93: FMTCOST08RELAMICAT\n",
      " 94: FMTCOST12RELAMICAT\n",
      " 95: FMTCOSTMEDRELAMICAT\n",
      " 96: FMTINCRELAMICAT\n",
      " 97: FMTASSISTED\n",
      " 98: FMTBURDEN\n",
      " 99: FMTREGION\n",
      "100: FMTSTATUS\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "# display all column numbers and names\n",
    "csvcut -n Combined_hud.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined_hud.csv\n",
      "Hud_2005.csv\n",
      "Hud_2007.csv\n",
      "Hud_2013.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "# Copy only seven columns to new file, rewrite original file with new file data, delete new file\n",
    "csvcut -c 1,3,45,8,80,78,34 Combined_hud.csv > newfile.csv && rm Combined_hud.csv && cp newfile.csv Combined_hud.csv && rm newfile.csv\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: year\n",
      "  2: AGE1\n",
      "  3: BURDEN\n",
      "  4: FMR\n",
      "  5: FMTBEDRMS\n",
      "  6: FMTBUILT\n",
      "  7: TOTSAL\n",
      "\n",
      "|  year | AGE1 |  BURDEN | FMR | FMTBEDRMS | FMTBUILT  | TOTSAL |\n",
      "| ----- | ---- | ------- | --- | --------- | --------- | ------ |\n",
      "| 2,005 |   43 |  0.513… | 680 | 3 3BR     | 1980-1989 | 20,000 |\n",
      "| 2,005 |   44 |  0.223… | 760 | 4 4BR+    | 1980-1989 | 71,000 |\n",
      "| 2,005 |   58 |  0.218… | 680 | 3 3BR     | 1980-1989 | 63,000 |\n",
      "| 2,005 |   22 |  0.217… | 519 | 1 1BR     | 1980-1989 | 27,040 |\n",
      "| 2,005 |   48 |  0.283… | 600 | 1 1BR     | 1980-1989 | 14,000 |\n",
      "| 2,005 |   42 |  0.292… | 788 | 3 3BR     | 1980-1989 | 42,000 |\n",
      "| 2,005 |   -9 | -9.000… | 702 | 2 2BR     | 1980-1989 |     -9 |\n",
      "| 2,005 |   23 |  0.145… | 546 | 2 2BR     | 1980-1989 | 48,000 |\n",
      "| 2,005 |   51 |  0.296… | 680 | 3 3BR     | 1980-1989 | 58,000 |\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "# display columns numbers and names\n",
    "csvcut -n Combined_hud.csv\n",
    "\n",
    "# display first 10 rows as table\n",
    "head Combined_hud.csv | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE1\n",
      "43\n",
      "44\n",
      "58\n",
      "22\n",
      "48\n",
      "42\n",
      "-9\n",
      "23\n",
      "51\n",
      "year\n",
      "2005\n",
      "2005\n",
      "2005\n",
      "2005\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "# display first 10 rows of AGE1 column by col number\n",
    "csvcut -c 2 Combined_hud.csv | head\n",
    "\n",
    "# display first 5 rows of year column by name\n",
    "csvcut -c year Combined_hud.csv | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Csvstat\n",
    "\n",
    "Now that we know how to select specific columns, we can select a column and pipe it to the csvstat tool to calculate summary statistics for that column:\n",
    "\n",
    "    csvcut -c 4 Combined_hud.csv | csvstat\n",
    "\n",
    "This calculates a full suite of summary statistics, including:\n",
    "\n",
    "- max,\n",
    "- min,\n",
    "- sum,\n",
    "- mean,\n",
    "- median,\n",
    "- standard deviation.\n",
    "\n",
    "Depending on the size of the data, the full summary statistics for a column can take a long time and you often just want a specific summary statistic. You can use -- flags to choose specific summary statistics, which will greatly improve the speed:\n",
    "\n",
    "    # Just the max value.\n",
    "    csvcut -c 2 Combined_hud.csv | csvstat --max\n",
    "    # Just the mean value.\n",
    "    csvcut -c 2 Combined_hud.csv | csvstat --mean\n",
    "    # Just the number of null values.\n",
    "    csvcut -c 2 Combined_hud.csv | csvstat --nulls\n",
    "    \n",
    "You can see a full list of flags in the documentation. If you want to calculate summary statistics over all the columns in a CSV file, you can pass the file to csvstat directly:\n",
    "\n",
    "    csvstat Combined_hud.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. year: 2,008.904\n",
      "  2. AGE1: 46.511\n",
      "  3. BURDEN: 5.304\n",
      "  4. FMR: 7,966.32\n",
      "  5. FMTBEDRMS: None\n",
      "  6. FMTBUILT: None\n",
      "  7. TOTSAL: 44,041.842\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "# mean for all columns\n",
    "csvstat --mean Combined_hud.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Csvcut | Csvstat\n",
    "\n",
    "Let's use csvcut and csvstat to search for any problematic values in the AGE1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. \"AGE1\"\n",
      "\n",
      "\tType of data:          Number\n",
      "\tContains null values:  False\n",
      "\tUnique values:         80\n",
      "\tSmallest value:        -9\n",
      "\tLargest value:         93\n",
      "\tSum:                   7,168,169\n",
      "\tMean:                  46.511\n",
      "\tMedian:                48\n",
      "\tStDev:                 23.049\n",
      "\tMost common values:    -9 (11553x)\n",
      "\t                       50 (3208x)\n",
      "\t                       45 (3056x)\n",
      "\t                       40 (3040x)\n",
      "\t                       48 (3006x)\n",
      "\n",
      "Row count: 154117\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "# all summary statistics for AGE1 column (notice problematic values)\n",
    "csvcut -c 2 Combined_hud.csv | csvstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Csvgrep\n",
    "You'll notice that -9 is the most common value in the AGE1 column, which is problematic since age values have to be greater than 0. We can use csvgrep to select all the rows that match a specific pattern to dive a bit deeper. By default, csvgrep will search all of the rows in the dataset but we can restrict the search to specific columns using the -c flag (just like with csvcut). We then use the -m flag to specify the pattern:\n",
    "\n",
    "    csvgrep -c 2 -m -9 Combined_hud.csv\n",
    "    \n",
    "This command will return all rows from Combined_hud.csv with -9 as the value for the AGE1 column. The behavior of csvgrep can be customized using the flags. For example, you can use the -r flag to pass in a regular expression as the pattern instead. We're now going to combined several of the tools we've talked about so far so that you can see the real power of using the csvkit tools combined with other CLI tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  year | AGE1 | BURDEN |   FMR | FMTBEDRMS | FMTBUILT  | TOTSAL |\n",
      "| ----- | ---- | ------ | ----- | --------- | --------- | ------ |\n",
      "| 2,005 |   -9 |     -9 |   702 | 2 2BR     | 1980-1989 |     -9 |\n",
      "| 2,005 |   -9 |     -9 |   531 | 1 1BR     | 1980-1989 |     -9 |\n",
      "| 2,005 |   -9 |     -9 | 1,034 | 3 3BR     | 2000-2009 |     -9 |\n",
      "| 2,005 |   -9 |     -9 |   631 | 1 1BR     | 1980-1989 |     -9 |\n",
      "| 2,005 |   -9 |     -9 |   712 | 4 4BR+    | 1990-1999 |     -9 |\n",
      "| 2,005 |   -9 |     -9 | 1,006 | 3 3BR     | 2000-2009 |     -9 |\n",
      "| 2,005 |   -9 |     -9 |   631 | 1 1BR     | 1980-1989 |     -9 |\n",
      "| 2,005 |   -9 |     -9 |   712 | 3 3BR     | 2000-2009 |     -9 |\n",
      "| 2,005 |   -9 |     -9 | 1,087 | 3 3BR     | 2000-2009 |     -9 |\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "# Display the first 10 rows from Combined_hud.csv where the value for the AGE1 column is -9 in table format.\n",
    "csvgrep -c 2 -m -9 Combined_hud.csv | head | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8: Filtering Out Problematic Rows\n",
    "\n",
    "Let's now filter out all of these problematic rows from the dataset since they have data quality issues. Csvkit wasn't developed with a sharp focus on editing existing files, and the easiest way to filter rows is to create a separate file with just the rows we're interested in. To accomplish this, we can redirect the output of csvgrep to a file. So far, we've only used csvgrep to select rows that match a specific pattern. We need to instead select the rows that don't match a pattern, which we can specify with the -i flag. You can read more about this flag in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year,AGE1,BURDEN,FMR,FMTBEDRMS,FMTBUILT,TOTSAL\n",
      "2005,43,0.513,680,'3 3BR','1980-1989',20000\n",
      "2005,44,0.2225915493,760,'4 4BR+','1980-1989',71000\n",
      "2005,58,0.2178312657,680,'3 3BR','1980-1989',63000\n",
      "2005,22,0.2174556213,519,'1 1BR','1980-1989',27040\n",
      "2005,48,0.2828571429,600,'1 1BR','1980-1989',14000\n",
      "2005,42,0.2922857143,788,'3 3BR','1980-1989',42000\n",
      "2005,23,0.14475,546,'2 2BR','1980-1989',48000\n",
      "2005,51,0.2962,680,'3 3BR','1980-1989',58000\n",
      "2005,47,0.1896,1081,'4 4BR+','2000-2009',125000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "\n",
    "# csvgrep -i flag inverts the selection (rows where pattern does not match)\n",
    "csvgrep -c 2 -m -9 -i Combined_hud.csv > positive_ages_only.csv\n",
    "# display first 10 rows\n",
    "head positive_ages_only.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9: Next Steps\n",
    "\n",
    "In this challenge, you learned how to use the csvkit library to explore and clean CSV files. You should use csvkit whenever you need to quickly transform or explore data from the command line, but remember that it has a few limitations:\n",
    "\n",
    "- Csvkit is not optimized for speed and struggles to run some commands over larger files.\n",
    "\n",
    "- Csvkit has very limited capabilities for actually editing problematic values in a dataset, since the community behind the library aspired to keep the library small and lightweight."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
